"","title","author","subject","abstract","date"
"1","On the Complexity of Community-aware Network Sparsification","Emanuel Herrendorf, Christian Komusiewicz, Nils Morawietz, Frank Sommer","Data Structures and Algorithms (cs.DS)","Network sparsification is the task of reducing the number of edges of a given graph while preserving some crucial graph property. In communityaware network sparsification, the preserved property concerns the subgraphs that are induced by the communities of the graph which are given as vertex subsets. This is formalized in the PiNetwork Sparsification problem given an edgeweighted graph G, a collection Z of c subsets of VG communities, and two numbers ell, b, the question is whether there exists a spanning subgraph G of G with at most ell edges of total weight at most b such that GC fulfills Pi for each community C. Here, we consider two graph properties Pi the connectivity property Connectivity NWS and the property of having a spanning star Stars NWS. Since both problems are NPhard, we study their parameterized and finegrained complexity. We provide a tight 2Omegan2c polynZtime running time lower bound based on the ETH for both problems, where n is the number of vertices in G. The lower bound holds even in the restricted case when all communities have size at most 4, G is a clique, and every edge has unit weight. For the connectivity property, the unit weight case with G being a clique is the wellstudied problem of computing a hypergraph support with a minimum number of edges. We then study the complexity of both problems parameterized by the feedback edge number t of the solution graph G. For Stars NWS, we present an XPalgorithm for t. This answers an open question by Korach and Stern Disc. Appl. Math. 08 who asked for the existence of polynomialtime algorithms for t0. In contrast, we show for Connectivity NWS that known polynomialtime algorithms for t0 Korach and Stern, Math. Program. 03 Klemz et al., SWAT 14 cannot be extended by showing that Connectivity NWS is NPhard for t1.","Fri, 23 Feb 2024 18:32:39 UTC (165 KB)"
"2","Graph Partitioning With Limited Moves","Majid Behbahani, Mina Dalirrooyfard, Elaheh Fata, Yuriy Nevmyvaka","Data Structures and Algorithms (cs.DS)","In many real world networks, there already exists a not necessarily optimal kpartitioning of the network. Oftentimes, one aims to find a kpartitioning with a smaller cut value for such networks by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such realworld applications, we introduce and study the rmove kpartitioningproblem, a natural variant of the Multiway cut problem. Given a graph, a set of k terminals and an initial partitioning of the graph, the rmove kpartitioningproblem aims to find a kpartitioning with the minimumweighted cut among all the kpartitionings that can be obtained by moving at most r nonterminal nodes to partitions different from their initial ones. Our main result is a polynomial time 3r1 approximation algorithm for this problem. We further show that this problem is W1hard, and give an FPTAS for when r is a small constant.","Fri, 23 Feb 2024 18:25:54 UTC (757 KB)"
"3","Lasso with Latents: Efficient Estimation, Covariate Rescaling, and Computational-Statistical Gaps","Jonathan Kelner, Frederic Koehler, Raghu Meka, Dhruv Rohatgi","Machine Learning (stat.ML)","It is wellknown that the statistical performance of Lasso can suffer significantly when the covariates of interest have strong correlations. In particular, the prediction error of Lasso becomes much worse than computationally inefficient alternatives like Best Subset Selection. Due to a large conjectured computationalstatistical tradeoff in the problem of sparse linear regression, it may be impossible to close this gap in general. In this work, we propose a natural sparse linear regression setting where strong correlations between covariates arise from unobserved latent variables. In this setting, we analyze the problem caused by strong correlations and design a surprisingly simple fix. While Lasso with standard normalization of covariates fails, there exists a heterogeneous scaling of the covariates with which Lasso will suddenly obtain strong provable guarantees for estimation. Moreover, we design a simple, efficient procedure for computing such a smart scaling. The sample complexity of the resulting rescaled Lasso algorithm incurs in the worst case quadratic dependence on the sparsity of the underlying signal. While this dependence is not informationtheoretically necessary, we give evidence that it is optimal among the class of polynomialtime algorithms, via the method of lowdegree polynomials. This argument reveals a new connection between sparse linear regression and a special version of sparse PCA with a nearcritical negative spike. The latter problem can be thought of as a realvalued analogue of learning a sparse parity. Using it, we also establish the first computationalstatistical gap for the closely related problem of learning a Gaussian Graphical Model.","Fri, 23 Feb 2024 16:16:38 UTC (285 KB)"
"4","Tight Approximation and Kernelization Bounds for Vertex-Disjoint Shortest Paths","Matthias Bentert, Fedor V. Fomin, Petr A. Golovach","Data Structures and Algorithms (cs.DS)","We examine the possibility of approximating Maximum VertexDisjoint Shortest Paths. In this problem, the input is an edgeweighted directed or undirected nvertex graph G along with k terminal pairs s1,t1,s2,t2,ldots,sk,tk. The task is to connect as many terminal pairs as possible by pairwise vertexdisjoint paths such that each path is a shortest path between the respective terminals. Our work is anchored in the recent breakthrough by Lochet SODA 21, which demonstrates the polynomialtime solvability of the problem for a fixed value of k. Lochets result implies the existence of a polynomialtime ckapproximation for Maximum VertexDisjoint Shortest Paths, where c leq 1 is a constant. Our first result suggests that this approximation algorithm is, in a sense, the best we can hope for. More precisely, assuming the gapETH, we exclude the existence of an okapproximations within fk cdot polyn time for any function f that only depends on k. Our second result demonstrates the infeasibility of achieving an approximation ratio of nfrac12varepsilon in polynomial time, unless P  NP. It is not difficult to show that a greedy algorithm selecting a path with the minimum number of arcs results in a lceilsqrtellrceilapproximation, where ell is the number of edges in all the paths of an optimal solution. Since ell leq n, this underscores the tightness of the nfrac12varepsiloninapproximability bound. Additionally, we establish that Maximum VertexDisjoint Shortest Paths is fixedparameter tractable when parameterized by ell but does not admit a polynomial kernel. Our hardness results hold for undirected graphs with unit weights, while our positive results extend to scenarios where the input graph is directed and features arbitrary nonnegative edge weights.","Fri, 23 Feb 2024 14:31:52 UTC (25 KB)"
"5","Platforms for Efficient and Incentive-Aware Collaboration","Nika Haghtalab, Mingda Qiao, Kunhe Yang","Computer Science and Game Theory (cs.GT)","Collaboration is crucial for reaching collective goals. However, its effectiveness is often undermined by the strategic behavior of individual agents  a fact that is captured by a high Price of Stability PoS in recent literature Blum et al., 2021. Implicit in the traditional PoS analysis is the assumption that agents have full knowledge of how their tasks relate to one another. We offer a new perspective on bringing about efficient collaboration among strategic agents using information design. Inspired by the growing importance of collaboration in machine learning such as platforms for collaborative federated learning and data cooperatives, we propose a framework where the platform has more information about how the agents tasks relate to each other than the agents themselves. We characterize how and to what degree such platforms can leverage their information advantage to steer strategic agents toward efficient collaboration. Concretely, we consider collaboration networks where each node is a task type held by one agent, and each task benefits from contributions made in their inclusive neighborhood of tasks. This network structure is known to the agents and the platform, but only the platform knows each agents real location  from the agents perspective, their location is determined by a random permutation. We employ private Bayesian persuasion and design two families of persuasive signaling schemes that the platform can use to ensure a small total workload when agents follow the signal. The first family aims to achieve the minmax optimal approximation ratio compared to the optimal collaboration, which is shown to be Thetasqrtn for unitweight graphs, Thetan23 for graphs with constant minimum edge weights, and On34 for general weighted graphs. The second family ensures perinstance strict improvement compared to full information disclosure.","Fri, 23 Feb 2024 08:04:23 UTC (62 KB)"
"6","Algorithmically Fair Maximization of Multiple Submodular Objective Functions","Georgios Amanatidis, Georgios Birmpas, Philip Lazos, Stefano Leonardi, Rebecca Reiffenhäuser","Data Structures and Algorithms (cs.DS)","Constrained maximization of submodular functions poses a central problem in combinatorial optimization. In many realistic scenarios, a number of agents need to maximize multiple submodular objectives over the same ground set. We study such a setting, where the different solutions must be disjoint, and thus, questions of fairness arise. Inspired from the fair division literature, we suggest a simple roundrobin protocol, where agents are allowed to build their solutions one item at a time by taking turns. Unlike what is typical in fair division, however, the prime goal here is to provide a fair algorithmic environment each agent is allowed to use any algorithm for constructing their respective solutions. We show that just by following simple greedy policies, agents have solid guarantees for both monotone and nonmonotone objectives, and for combinatorial constraints as general as psystems which capture cardinality and matroid intersection constraints. In the monotone case, our results include approximate EF1type guarantees and their implications in fair division may be of independent interest. Further, although following a greedy policy may not be optimal in general, we show that consistently performing better than that is computationally hard.","Fri, 23 Feb 2024 07:37:05 UTC (389 KB)"
"7","The Cost of Parallelizing Boosting","Xin Lyu, Hongxun Wu, Junzhao Yang","Machine Learning (cs.LG)","We study the cost of parallelizing weaktostrong boosting algorithms for learning, following the recent work of Karbasi and Larsen. Our main results are twofold  First, we prove a tight lower bound, showing that even slight parallelization of boosting requires an exponential blowup in the complexity of training. Specifically, let gamma be the weak learners advantage over random guessing. The famous textscAdaBoost algorithm produces an accurate hypothesis by interacting with the weak learner for tildeO1  gamma2 rounds where each round runs in polynomial time. Karbasi and Larsen showed that significant parallelization must incur exponential blowup Any boosting algorithm either interacts with the weak learner for Omega1  gamma rounds or incurs an expd  gamma blowup in the complexity of training, where d is the VC dimension of the hypothesis class. We close the gap by showing that any boosting algorithm either has Omega1  gamma2 rounds of interaction or incurs a smaller exponential blowup of expd. Complementing our lower bound, we show that there exists a boosting algorithm using tildeO1t gamma2 rounds, and only suffer a blowup of expd cdot t2. Plugging in t  omega1, this shows that the smaller blowup in our lower bound is tight. More interestingly, this provides the first tradeoff between the parallelism and the total work required for boosting.","Fri, 23 Feb 2024 07:03:52 UTC (25 KB)"
"8","The Umeyama algorithm for matching correlated Gaussian geometric models in the low-dimensional regime","Shuyang Gong, Zhangsong Li","Statistics Theory (math.ST)","Motivated by the problem of matching two correlated random geometric graphs, we study the problem of matching two Gaussian geometric models correlated through a latent node permutation. Specifically, given an unknown permutation pi on 1,ldots,n and given n i.i.d. pairs of correlated Gaussian vectors Xpii,Yi in mathbbRd with noise parameter sigma, we consider two types of correlated weighted complete graphs with edge weights given by Ai,jlangle Xi,Xj rangle, Bi,jlangle Yi,Yj rangle. The goal is to recover the hidden vertex correspondence pi based on the observed matrices A and B. For the lowdimensional regime where dOlog n, Wang, Wu, Xu, and Yolou WWXY22 established the information thresholds for exact and almost exact recovery in matching correlated Gaussian geometric models. They also conducted numerical experiments for the classical Umeyama algorithm. In our work, we prove that this algorithm achieves exact recovery of pi when the noise parameter sigmaod3n2d, and almost exact recovery when sigmaod3n1d. Our results approach the information thresholds up to a operatornamepolyd factor in the lowdimensional regime.","Fri, 23 Feb 2024 04:58:54 UTC (32 KB)"
"9","Tight Inapproximability of Target Set Reconfiguration","Naoto Ohsaka","Data Structures and Algorithms (cs.DS)","Given a graph G with a vertex threshold function tau, consider a dynamic process in which any inactive vertex v becomes activated whenever at least tauv of its neighbors are activated. A vertex set S is called a target set if all vertices of G would be activated when initially activating vertices of S. In the Minmax Target Set Reconfiguration problem, for a graph G and its two target sets X and Y, we wish to transform X into Y by repeatedly adding or removing a single vertex, using only target sets of G, so as to minimize the maximum size of any intermediate target set. We prove that it is NPhard to approximate Minmax Target Set Reconfiguration within a factor of 2oleftfrac1operatornamepolylog nright, where n is the number of vertices. Our result establishes a tight lower bound on approximability of Minmax Target Set Reconfiguration, which admits a 2factor approximation algorithm. The proof is based on a gappreserving reduction from Target Set Selection to Minmax Target Set Reconfiguration, where NPhardness of approximation for the former problem is proven by Chen SIAM J. Discrete Math., 2009 and Charikar, Naamad, and Wirth APPROXRANDOM 2016.","Fri, 23 Feb 2024 03:35:36 UTC (21 KB)"
"10","Repro Samples Method for a Performance Guaranteed Inference in General and Irregular Inference Problems","Minge Xie, Peng Wang","Methodology (stat.ME)","Rapid advancements in data science require us to have fundamentally new frameworks to tackle prevalent but highly nontrivial irregular inference problems, to which the large sample central limit theorem does not apply. Typical examples are those involving discrete or nonnumerical parameters and those involving nonnumerical data, etc. In this article, we present an innovative, widereaching, and effective approach, called repro samples method, to conduct statistical inference for these irregular problems plus more. The development relates to but improves several existing simulationinspired inference approaches, and we provide both exact and approximate theories to support our development. Moreover, the proposed approach is broadly applicable and subsumes the classical NeymanPearson framework as a special case. For the oftenseen irregular inference problems that involve both discretenonnumerical and continuous parameters, we propose an effective threestep procedure to make inferences for all parameters. We also develop a unique matching scheme that turns the discreteness of discretenonnumerical parameters from an obstacle for forming inferential theories into a beneficial attribute for improving computational efficiency. We demonstrate the effectiveness of the proposed general methodology using various examples, including a case study example on a Gaussian mixture model with unknown number of components. This case study example provides a solution to a longstanding open inference question in statistics on how to quantify the estimation uncertainty for the unknown number of components and other associated parameters. Real data and simulation studies, with comparisons to existing approaches, demonstrate the far superior performance of the proposed method.","Thu, 22 Feb 2024 22:43:42 UTC (384 KB)"
"11","Parallel Approximate Maximum Flows in Near-Linear Work and Polylogarithmic Depth","Arpit Agarwal, Sanjeev Khanna, Huan Li, Prathamesh Patil, Chen Wang, Nathan White, Peilin Zhong","Data Structures and Algorithms (cs.DS)","We present a parallel algorithm for the 1epsilonapproximate maximum flow problem in capacitated, undirected graphs with n vertices and m edges, achieving Oepsilon3textpolylog n depth and Om epsilon3 textpolylog n work in the PRAM model. Although nearlinear time sequential algorithms for this problem have been known for almost a decade, no parallel algorithms that simultaneously achieved polylogarithmic depth and nearlinear work were known. At the heart of our result is a polylogarithmic depth, nearlinear work recursive algorithm for computing congestion approximators. Our algorithm involves a recursive step to obtain a lowquality congestion approximator followed by a boosting step to improve its quality which prevents a multiplicative blowup in error. Similar to Peng SODA16, our boosting step builds upon the hierarchical decomposition scheme of Rcke, Shah, and Tubig SODA14. A direct implementation of this approach, however, leads only to an algorithm with no1 depth and m1o1 work. To get around this, we introduce a new hierarchical decomposition scheme, in which we only need to solve maximum flows on subgraphs obtained by contracting vertices, as opposed to vertexinduced subgraphs used in Rcke, Shah, and Tubig SODA14. In particular, we are able to directly extract congestion approximators for the subgraphs from a congestion approximator for the entire graph, thereby avoiding additional recursion on those subgraphs. Along the way, we also develop a parallel flowdecomposition algorithm that is crucial to achieving polylogarithmic depth and may be of independent interest.","Thu, 22 Feb 2024 20:23:59 UTC (97 KB)"
"12","Hitting Meets Packing: How Hard Can it Be?","Jacob Focke, Fabian Frei, Shaohua Li, Dániel Marx, Philipp Schepper, Roohani Sharma, Karol Węgrzycki","Data Structures and Algorithms (cs.DS)","We study a general family of problems that form a common generalization of classic hitting also referred to as covering or transversal and packing problems. An instance of XHitPack asks Can removing k deletable vertices of a graph G prevent us from packing ell vertexdisjoint objects of type X? This problem captures a spectrum of problems with standard hitting and packing on opposite ends. Our main motivating question is whether the combination XHitPack can be significantly harder than these two base problems. Already for a particular choice of X, this question can be posed for many different complexity notions, leading to a large, sofar unexplored domain in the intersection of the areas of hitting and packing problems. On a highlevel, we present two case studies 1 X being all cycles, and 2 X being all copies of a fixed graph H. In each, we explore the classical complexity, as well as the parameterized complexity with the natural parameters kl and treewidth. We observe that the combined problem can be drastically harder than the base problems for cycles or for H being a connected graph with at least 3 vertices, the problem is Sigma2Pcomplete and requires doubleexponential dependence on the treewidth of the graph assuming the ExponentialTime Hypothesis. In contrast, the combined problem admits qualitatively similar running times as the base problems in some cases, although significant novel ideas are required. For example, for X being all cycles, we establish a 2polyklnO1 algorithm using an involved branching method. Also, for X being all edges i.e., H  K2 this combines Vertex Cover and Maximum Matching the problem can be solved in time 2polytwnO1 on graphs of treewidth tw. The key step enabling this running time relies on a combinatorial bound obtained from an algebraic linear deltamatroid representation of possible matchings.","Thu, 22 Feb 2024 19:19:52 UTC (417 KB)"
"13","Time Efficient Implementation for Online $k$-server Problem on Trees","Kamil Khadiev, Maxim Yagafarov","Data Structures and Algorithms (cs.DS)","We consider online algorithms for the kserver problem on trees of size n. Chrobak and Larmore proposed a kcompetitive algorithm for this problem that has the optimal competitive ratio. However, the existing implementations have Oleftk2  kcdot log nright or Oleftklog n2right time complexity for processing a query, where n is the number of nodes. We propose a new timeefficient implementation of this algorithm that has On time complexity for preprocessing and Oleftklog kright time for processing a query. The new algorithm is faster than both existing algorithms and the time complexity for query processing does not depend on the tree size.","Thu, 22 Feb 2024 15:27:58 UTC (165 KB)"
"14","Approximate Circular Pattern Matching under Edit Distance","Panagiotis Charalampopoulos, Solon P. Pissis, Jakub Radoszewski, Wojciech Rytter, Tomasz Waleń, Wiktor Zuba","Data Structures and Algorithms (cs.DS)","In the kEdit Circular Pattern Matching kEdit CPM problem, we are given a lengthn text T, a lengthm pattern P, and a positive integer threshold k, and we are to report all starting positions of the substrings of T that are at edit distance at most k from some cyclic rotation of P. In the decision version of the problem, we are to check if any such substring exists. Very recently, Charalampopoulos et al. ESA 2022 presented Onk2time and Onk log3 ktime solutions for the reporting and decision versions of kEdit CPM, respectively. Here, we show that the reporting and decision versions of kEdit CPM can be solved in Onnm k6 time and Onnm k5 log3 k time, respectively, thus obtaining the first algorithms with a complexity of the type Onnm mathrmpolyk for this problem. Notably, our algorithms run in On time when mOmegak6 and are superior to the previous respective solutions when momegak4. We provide a metaalgorithm that yields efficient algorithms in several other interesting settings, such as when the strings are given in a compressed form as straightline programs, when the strings are dynamic, or when we have a quantum computer. We obtain our solutions by exploiting the structure of approximate circular occurrences of P in T, when T is relatively short w.r.t. P. Roughly speaking, either the starting positions of approximate occurrences of rotations of P form Ok4 intervals that can be computed efficiently, or some rotation of P is almost periodic is at a small edit distance from a string with small period. Dealing with the almost periodic case is the most technically demanding part of this work we tackle it using properties of locked fragments originating from Cole and Hariharan, SICOMP 2002.","Thu, 22 Feb 2024 13:42:47 UTC (280 KB)"
"15","An Improved Pseudopolynomial Time Algorithm for Subset Sum","Lin Chen, Jiayi Lian, Yuchen Mao, Guochuan Zhang","Data Structures and Algorithms (cs.DS)","We investigate pseudopolynomial time algorithms for Subset Sum. Given a multiset X of n positive integers and a target t, Subset Sum asks whether some subset of X sums to t. Bringmann proposes an tildeOn  ttime algorithm Bringmann SODA17, and an open question has naturally arisen can Subset Sum be solved in On  w time? Here w is the maximum integer in X. We make a progress towards resolving the open question by proposing an tildeOn  sqrtwttime algorithm.","Thu, 22 Feb 2024 12:38:42 UTC (26 KB)"
"16","Data Science with LLMs and Interpretable Models","Sebastian Bordt, Ben Lengerich, Harsha Nori, Rich Caruana","Machine Learning (cs.LG)","Recent years have seen important advances in the building of interpretable models, machine learning models that are designed to be easily understood by humans. In this work, we show that large language models LLMs are remarkably good at working with interpretable models, too. In particular, we show that LLMs can describe, interpret, and debug Generalized Additive Models GAMs. Combining the flexibility of LLMs with the breadth of statistical patterns accurately described by GAMs enables dataset summarization, question answering, and model critique. LLMs can also improve the interaction between domain experts and interpretable models, and generate hypotheses about the underlying phenomenon. We release urlthis https URL as an opensource LLMGAM interface.","Thu, 22 Feb 2024 12:04:15 UTC (427 KB)"
"17","Parameterized Complexity of Finding Dissimilar Shortest Paths","Ryo Funayama, Yasuaki Kobayashi, Takeaki Uno","Data Structures and Algorithms (cs.DS)","We consider the problem of finding dissimilar k shortest paths from s to t in an edgeweighted directed graph D, where the dissimilarity is measured by the minimum pairwise Hamming distances between these paths. More formally, given an edgeweighted directed graph D  V, A, two specified vertices s, t in V, and integers d, k, the goal of Dissimilar Shortest Paths is to decide whether D has k shortest paths P1, dots, Pk from s to t such that APi mathbintriangle APj ge d for distinct Pi and Pj. We design a deterministic algorithm to solve Dissimilar Shortest Paths with running time 2O3kdk2nO1, that is, Dissimilar Shortest Paths is fixedparameter tractable parameterized by k  d. To complement this positive result, we show that Dissimilar Shortest Paths is W1hard when parameterized by only k and paraNPhard parameterized by d.","Thu, 22 Feb 2024 08:40:03 UTC (687 KB)"
"18","Extention of Bagging MARS with Group LASSO for Heterogeneous Treatment Effect Estimation","Guanwenqing He, Ke Wan, Kazushi Maruo, Toshio Shimokawa","Methodology (stat.ME)","Recent years, large scale clinical data like patient surveys and medical record data are playing an increasing role in medical data science. These largescale clinical data, collectively referred to as realworld data RWD. It is expected to be widely used in largescale observational studies of specific diseases, personal medicine or precise medicine, finding the responder of drugs or treatments. Applying RWD for estimating heterogeneous treat ment effect HTE has already been a trending topic. HTE has the potential to considerably impact the development of precision medicine by helping doctors make more informed precise treatment decisions and provide more personalized medical care. The statistical models used to estimate HTE is called treatment effect models. Powers et al. proposed a some treatment effect models for observational study, where they pointed out that the bagging causal MARS BCM performs outstanding compared to other models. While BCM has excellent performance, it still has room for improvement. In this paper, we proposed a new treatment effect model called shrinkage causal bagging MARS method to improve their shared basis conditional mean regression framework based on the following points first, we estimated basis functions using transformed outcome, then applied the group LASSO method to optimize the model and estimate parameters. Besides, we are focusing on pursing better interpretability of model to improve the ethical acceptance. We designed simulations to verify the performance of our proposed method and our proposed method superior in mean square error and bias in most simulation settings. Also we applied it to real data set ACTG 175 to verify its usability, where our results are supported by previous studies.","Thu, 22 Feb 2024 04:47:22 UTC (2,962 KB)"
"19","Locality Bounds for Sampling Hamming Slices","Daniel M. Kane, Anthony Ostuni, Kewen Wu","Computational Complexity (cs.CC)","Spurred by the influential work of Viola Journal of Computing 2012, the past decade has witnessed an active line of research into the complexity of approximately sampling distributions, in contrast to the traditional focus on the complexity of computing functions. We build upon and make explicit earlier implicit results of Viola to provide superconstant lower bounds on the locality of Boolean functions approximately sampling the uniform distribution over binary strings of particular Hamming weights, both exactly and modulo an integer, answering questions of Viola Journal of Computing 2012 and Filmus, Leigh, Riazanov, and Sokolov RANDOM 2023. Applications to data structure lower bounds and quantumclassical separations are discussed.","Thu, 22 Feb 2024 04:36:49 UTC (416 KB)"
"20","Sample-Efficient Linear Regression with Self-Selection Bias","Jason Gaitonde, Elchanan Mossel","Statistics Theory (math.ST)","We consider the problem of linear regression with selfselection bias in the unknownindex setting, as introduced in recent work by Cherapanamjeri, Daskalakis, Ilyas, and Zampetakis STOC 2023. In this model, one observes m i.i.d. samples mathbfxell,zellell1m where zellmaxiin kmathbfxellTmathbfwietai,ell, but the maximizing index iell is unobserved. Here, the mathbfxell are assumed to be mathcalN0,In and the noise distribution mathbfetaellsim mathcalD is centered and independent of mathbfxell. We provide a novel and near optimally sampleefficient in terms of k algorithm to recover mathbfw1,ldots,mathbfwkin mathbbRn up to additive ell2error varepsilon with polynomial sample complexity tildeOncdot mathsfpolyk,1varepsilon and significantly improved time complexity mathsfpolyn,k,1varepsilonOlogkvarepsilonOk. When kO1, our algorithm runs in mathsfpolyn,1varepsilon time, generalizing the polynomial guarantee of an explicit moment matching algorithm of Cherapanamjeri, et al. for k2 and when it is known that mathcalDmathcalN0,Ik. Our algorithm succeeds under significantly relaxed noise assumptions, and therefore also succeeds in the related setting of maxlinear regression where the added noise is taken outside the maximum. For this problem, our algorithm is efficient in a much larger range of k than the stateoftheart due to Ghosh, Pananjady, Guntuboyina, and Ramchandran IEEE Trans. Inf. Theory 2022 for not too small varepsilon, and leads to improved algorithms for any varepsilon by providing a warm start for existing local convergence methods.","Thu, 22 Feb 2024 02:20:24 UTC (46 KB)"
"21","Random-Order Online Interval Scheduling and Geometric Generalizations","Mohit Garg, Debajyoti Kar, Arindam Khan","Data Structures and Algorithms (cs.DS)","In the Maximum Independent Set of Hyperrectangles problem, we are given a set of n possibly overlapping ddimensional axisaligned hyperrectangles, and the goal is to find a subset of nonoverlapping hyperrectangles of maximum cardinality. For d1, this corresponds to the classical Interval Scheduling problem, where a simple greedy algorithm returns an optimal solution. In the offline setting, for ddimensional hyperrectangles, polynomial time log nOdapproximation algorithms are known. However, the problem becomes notably challenging in the online setting, where the input objects hyperrectangles appear one by one in an adversarial order, and on the arrival of an object, the algorithm needs to make an immediate and irrevocable decision whether or not to select the object while maintaining the feasibility. Even for interval scheduling, an Omegan lower bound is known on the competitive ratio. To circumvent these negative results, in this work, we study the online maximum independent set of axisaligned hyperrectangles in the randomorder arrival model, where the adversary specifies the set of input objects which then arrive in a uniformly random order. Starting from the prototypical secretary problem, the randomorder model has received significant attention to study algorithms beyond the worstcase competitive analysis. Surprisingly, we show that the problem in the randomorder model almost matches the bestknown offline approximation guarantees, up to polylogarithmic factors. In particular, we give a simple log nOdcompetitive algorithm for ddimensional hyperrectangles in this model, which runs in tildeOdn time. Our approach also yields log nOdcompetitive algorithms in the randomorder model for more general objects such as ddimensional fat objects and ellipsoids.","Thu, 22 Feb 2024 01:04:18 UTC (47 KB)"
"22","Masked Matrix Multiplication for Emergent Sparsity","Brian Wheatman, Meghana Madhyastha, Randal Burns","Data Structures and Algorithms (cs.DS)","Artificial intelligence workloads, especially transformer models, exhibit emergent sparsity in which computations perform selective sparse access to dense data. The workloads are inefficient on hardware designed for dense computations and do not map well onto sparse data representations. We build a vectorized and parallel matrixmultiplication system A X B  C that eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity. We use a combination of dynamic code lookup to adapt to the specific sparsity encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to compute conditional branches once for the whole computation. For a wide range of sparsity, from 60 to 95 zeros, our implementation performs fewer instructions and increases performance when compared with Intel MKLs dense or sparse matrix multiply routines. Benefits can be as large as 2 times speedup and 4 times fewer instructions.","Wed, 21 Feb 2024 20:36:08 UTC (823 KB)"
"23","Probability Tools for Sequential Random Projection","Yingru Li","Statistics Theory (math.ST)","We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decisionmaking under uncertainty. The analysis is complicated by the sequential dependence and highdimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a selfnormalized process, derived from the stopped process, we achieve a desired nonasymptotic probability bound. This bound represents a nontrivial martingale extension of the JohnsonLindenstrauss JL lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.","Fri, 16 Feb 2024 13:17:13 UTC (21 KB)"
"24","Misalignment, Learning, and Ranking: Harnessing Users Limited Attention","Arpit Agarwal, Rad Niazadeh, Prathamesh Patil","Machine Learning (cs.LG)","In digital health and EdTech, recommendation systems face a significant challenge users often choose impulsively, in ways that conflict with the platforms longterm payoffs. This misalignment makes it difficult to effectively learn to rank items, as it may hinder exploration of items with greater longterm payoffs. Our paper tackles this issue by utilizing users limited attention spans. We propose a model where a platform presents items with unknown payoffs to the platform in a ranked list to T users over time. Each user selects an item by first considering a prefix window of these ranked items and then picking the highest preferred item in that window and the platform observes its payoff for this item. We study the design of online bandit algorithms that obtain vanishing regret against hindsight optimal benchmarks. We first consider adversarial window sizes and stochastic iid payoffs. We design an activeeliminationbased algorithm that achieves an optimal instancedependent regret bound of OlogT, by showing matching regret upper and lower bounds. The key idea is using the combinatorial structure of the problem to either obtain a large payoff from each item or to explore by getting a sample from that item. This method systematically narrows down the item choices to enhance learning efficiency and payoff. Second, we consider adversarial payoffs and stochastic iid window sizes. We start from the fullinformation problem of finding the permutation that maximizes the expected payoff. By a novel combinatorial argument, we characterize the polytope of admissible item selection probabilities by a permutation and show it has a polynomialsize representation. Using this representation, we show how standard algorithms for adversarial online linear optimization in the space of admissible probabilities can be used to obtain a polynomialtime algorithm with OsqrtT regret.","Wed, 21 Feb 2024 18:52:20 UTC (45 KB)"
"25","Chasing Convex Functions with Long-term Constraints","Adam Lechowicz, Nicolas Christianson, Bo Sun, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy","Data Structures and Algorithms (cs.DS)","We introduce and study a family of online metric problems with longterm constraints. In these problems, an online player makes decisions mathbfxt in a metric space X,d to simultaneously minimize their hitting cost ftmathbfxt and switching cost as determined by the metric. Over the time horizon T, the player must satisfy a longterm demand constraint sumt cmathbfxt geq 1, where cmathbfxt denotes the fraction of demand satisfied at time t. Such problems can find a wide array of applications to online resource allocation in sustainable energy and computing systems. We devise optimal competitive and learningaugmented algorithms for specific instantiations of these problems, and further show that our proposed algorithms perform well in numerical experiments.","Wed, 21 Feb 2024 18:51:42 UTC (220 KB)"
"26","On Distributed Computation of the Minimum Triangle Edge Transversal","Keren Censor-Hillel, Majd Khoury","Distributed, Parallel, and Cluster Computing (cs.DC)","The distance of a graph from being trianglefree is a fundamental graph parameter, counting the number of edges that need to be removed from a graph in order for it to become trianglefree. Its corresponding computational problem is the classic minimum triangle edge transversal problem, and its normalized value is the baseline for trianglefreeness testing algorithms. While trianglefreeness testing has been successfully studied in the distributed setting, computing the distance itself in a distributed setting is unknown, to the best of our knowledge, despite being wellstudied in the centralized setting. This work addresses the computation of the minimum triangle edge transversal in distributed networks. We show with a simple warmup construction that this is a global task, requiring OmegaD rounds even in the mathsfLOCAL model with unbounded messages, where D is the diameter of the network. However, we show that approximating this value can be done much faster. A 1epsilonapproximation can be obtained in textpolylogn rounds, where n is the size of the network graph. Moreover, faster approximations can be obtained, at the cost of increasing the approximation factor to roughly 3, by a reduction to the minimum hypergraph vertex cover problem. With a time overhead of the maximum degree Delta, this can also be applied to the mathsfCONGEST model, in which messages are bounded. Our key technical contribution is proving that computing an exact solution is as hard as it gets in mathsfCONGEST, requiring a nearquadratic number of rounds. Because this problem is an edge selection problem, as opposed to previous lower bounds that were for node selection problems, major challenges arise in constructing the lower bound, requiring us to develop novel ingredients.","Wed, 21 Feb 2024 18:14:24 UTC (1,145 KB)"
"27","A $(5/3+ε)$-Approximation for Tricolored Non-crossing Euclidean TSP","Júlia Baligács, Yann Disser, Andreas Emil Feldmann, Anna Zych-Pawlewicz","Data Structures and Algorithms (cs.DS)","In the Tricolored Euclidean Traveling Salesperson problem, we are givenk3 sets of points in the plane and are looking for disjoint tours, each covering one of the sets. Arora 1998 famously gave a PTAS based on patching for the case k1 and, recently, Dross et al.2023 generalized this result tok2. Our contribution is a 53epsilonapproximation algorithm fork3 that further generalizes Aroras approach. It is believed that patching is generally no longer possible for more than two tours. We circumvent this issue by either applying a conditional patching scheme for three tours or using an alternative approach based on a weighted solution for k2.","Wed, 21 Feb 2024 17:07:04 UTC (129 KB)"
"28","Robust recovery for stochastic block models, simplified and generalized","Sidhanth Mohanty, Prasad Raghavendra, David X. Wu","Data Structures and Algorithms (cs.DS)","We study the problem of textitrobust community recovery efficiently recovering communities in sparse stochastic block models in the presence of adversarial corruptions. In the absence of adversarial corruptions, there are efficient algorithms when the textitsignaltonoise ratio exceeds the textitKestenStigum KS threshold, widely believed to be the computational threshold for this problem. The question we study is does the computational threshold for robust community recovery also lie at the KS threshold? We answer this question affirmatively, providing an algorithm for robust community recovery for arbitrary stochastic block models on any constant number of communities, generalizing the work of Ding, dOrsi, Nasser  Steurer on an efficient algorithm above the KS threshold in the case of 2community block models. There are three main ingredients to our work i The Bethe Hessian of the graph is defined as HGt triangleq DGIt2  AGt  I where DG is the diagonal matrix of degrees and AG is the adjacency matrix. Empirical work suggested that the Bethe Hessian for the stochastic block model has outlier eigenvectors corresponding to the communities right above the KestenStigum threshold. We formally confirm the existence of outlier eigenvalues for the Bethe Hessian, by explicitly constructing outlier eigenvectors from the community vectors. ii We develop an algorithm for a variant of robust PCA on sparse matrices. Specifically, an algorithm to partially recover top eigenspaces from adversarially corrupted sparse matrices under mild delocalization constraints. iii A rounding algorithm to turn vector assignments of vertices into a community assignment, inspired by the algorithm of Charikar  Wirth citeCW04 for 2XOR.","Wed, 21 Feb 2024 16:40:13 UTC (42 KB)"
"29","Practical algorithms for Hierarchical overlap graphs","Saumya Talera, Parth Bansal, Shabnam Khan, Shahbaz Khan","Data Structures and Algorithms (cs.DS)","Genome assembly is a prominent problem studied in bioinformatics, which computes the source string using a set of its overlapping substrings. Classically, genome assembly uses assembly graphs built using this set of substrings to compute the source string efficiently, having a tradeoff between scalability and avoiding information loss. The scalable de Bruijn graphs come at the price of losing crucial overlap information. The complete overlap information is stored in overlap graphs using quadratic space. Hierarchical overlap graphs IPL20 HOG overcome these limitations, avoiding information loss despite using linear space. After a series of suboptimal improvements, Khan and Park et al. simultaneously presented two optimal algorithms CPM2021, where only the former was seemingly practical. We empirically analyze all the practical algorithms for computing HOG, where the optimal algorithm CPM2021 outperforms the previous algorithms as expected, though at the expense of extra memory. However, it uses nonintuitive approach and nontrivial data structures. We present arguably the most intuitive algorithm, using only elementary arrays, which is also optimal. Our algorithm empirically proves even better for both time and memory over all the algorithms, highlighting its significance in both theory and practice. We further explore the applications of hierarchical overlap graphs to solve various forms of suffixprefix queries on a set of strings. Loukides et al. CPM2023 recently presented stateoftheart algorithms for these queries. However, these algorithms require complex blackbox data structures and are seemingly impractical. Our algorithms, despite failing to match the stateoftheart algorithms theoretically, answer different queries ranging from 0.01100 milliseconds for a data set having around a billion characters.","Wed, 21 Feb 2024 16:39:28 UTC (228 KB)"
"30","A Uniformly Random Solution to Algorithmic Redistricting","Jin-Yi Cai, Jacob Kruse, Kenneth Mayer, Daniel P. Szabo","Data Structures and Algorithms (cs.DS)","The process of drawing electoral district boundaries is known as political redistricting. Within this context, gerrymandering is the practice of drawing these boundaries such that they unfairly favor a particular political party, often leading to unequal representation and skewed electoral outcomes. One of the few ways to detect gerrymandering is by algorithmically sampling redistricting plans. Previous methods mainly focus on sampling from some neighborhood of realistic districting plans, rather than a uniform sample of the entire space. We present a deterministic subexponential time algorithm to uniformly sample from the space of all possible  k partitions of a bounded degree planar graph, and with this construct a sample of the entire space of redistricting plans. We also give a way to restrict this sample space to plans that match certain compactness and population constraints at the cost of added complexity. The algorithm runs in  2Osqrtnlog n  time, although we only give a heuristic implementation. Our method generalizes an algorithm to count selfavoiding walks on a square to count paths that split general planar graphs into  k  regions, and uses this to sample from the space of all  k partitions of a planar graph.","Wed, 21 Feb 2024 15:20:58 UTC (1,603 KB)"
"31","Diversity-Aware $k$-Maximum Inner Product Search Revisited","Qiang Huang, Yanhao Wang, Yiqun Sun, Anthony K. H. Tung","Information Retrieval (cs.IR)","The kMaximum Inner Product Search kMIPS serves as a foundational component in recommender systems and various data mining tasks. However, while most existing kMIPS approaches prioritize the efficient retrieval of highly relevant items for users, they often neglect an equally pivotal facet of search results emphdiversity. To bridge this gap, we revisit and refine the diversityaware kMIPS DkMIPS problem by incorporating two wellknown diversity objectives  minimizing the average and maximum pairwise item similarities within the results  into the original relevance objective. This enhancement, inspired by Maximal Marginal Relevance MMR, offers users a controllable tradeoff between relevance and diversity. We introduce textscGreedy and textscDualGreedy, two linear scanbased algorithms tailored for DkMIPS. They both achieve datadependent approximations and, when aiming to minimize the average pairwise similarity, textscDualGreedy attains an approximation ratio of 14 with an additive term for regularization. To further improve query efficiency, we integrate a lightweight BallCone Tree BCTree index with the two algorithms. Finally, comprehensive experiments on ten realworld data sets demonstrate the efficacy of our proposed methods, showcasing their capability to efficiently deliver diverse and relevant search results to users.","Wed, 21 Feb 2024 15:09:51 UTC (758 KB)"
"32","Multi-Agent Online Graph Exploration on Cycles and Tadpole Graphs","Erik van den Akker, Kevin Buchin, Klaus-Tycho Foerster","Data Structures and Algorithms (cs.DS)","We study the problem of multiagent online graph exploration, in which a team of k agents has to explore a given graph, starting and ending on the same node. The graph is initially unknown. Whenever a node is visited by an agent, its neighborhood and adjacent edges are revealed. The agents share a global view of the explored parts of the graph. The cost of the exploration has to be minimized, where cost either describes the time needed for the entire exploration time model, or the length of the longest path traversed by any agent energy model. We investigate graph exploration on cycles and tadpole graphs for 24 agents, providing optimal results on the competitive ratio in the energy model 1competitive with two agents on cycles and three agents on tadpole graphs, and for tadpole graphs in the time model 1.5competitive with four agents. We also show competitive upper bounds of 2 for the exploration of tadpole graphs with three agents, and 2.5 for the exploration of tadpole graphs with two agents in the time model.","Wed, 21 Feb 2024 14:43:34 UTC (28 KB)"
"33","Equilibria, Efficiency, and Inequality in Network Formation for Hiring and Opportunity","Cynthia Dwork, Chris Hays, Jon Kleinberg, Manish Raghavan","Computer Science and Game Theory (cs.GT)","Professional networks  the social networks among people in a given line of work  can serve as a conduit for job prospects and other opportunities. Here we propose a model for the formation of such networks and the transfer of opportunities within them. In our theoretical model, individuals strategically connect with others to maximize the probability that they receive opportunities from them. We explore how professional networks balance connectivity, where connections facilitate opportunity transfers to those who did not get them from outside sources, and congestion, where some individuals receive too many opportunities from their connections and waste some of them. We show that strategic individuals are overconnected at equilibrium relative to a social optimum, leading to a price of anarchy for which we derive nearly tight asymptotic bounds. We also show that, at equilibrium, individuals form connections to those who provide similar benefit to them as they provide to others. Thus, our model provides a microfoundation in professional networking contexts for the fundamental sociological principle of homophily, that similarity breeds connection, which in our setting is realized as a form of status homophily based on alignment in individual benefit. We further explore how, even if individuals are a priori equally likely to receive opportunities from outside sources, equilibria can be unequal, and we provide nearly tight bounds on how unequal they can be. Finally, we explore the ability for online platforms to intervene to improve social welfare and show that natural heuristics may result in adverse effects at equilibrium. Our simple model allows for a surprisingly rich analysis of coordination problems in professional networks and suggests many directions for further exploration.","Wed, 21 Feb 2024 14:38:37 UTC (6,769 KB)"
"34","Adaptive Massively Parallel Coloring in Sparse Graphs","Rustam Latypov, Yannic Maus, Shreyas Pai, Jara Uitto","Distributed, Parallel, and Cluster Computing (cs.DC)","Classic symmetrybreaking problems on graphs have gained a lot of attention in models of modern parallel computation. The Adaptive Massively Parallel Computation AMPC is a model that captures central challenges in data center computations. Chang et al. PODC2019 gave an extremely fast, constant time, algorithm for the Delta  1coloring problem, where Delta is the maximum degree of an input graph of n nodes. The algorithm works in the most restrictive lowspace setting, where each machine has ndelta local space for a constant 0  delta  1. In this work, we study the vertexcoloring problem in sparse graphs parameterized by their arboricity alpha, a standard measure for sparsity. We give deterministic algorithms that in constant, or almost constant, time give textpolyalpha and Oalphacolorings, where alpha can be arbitrarily smaller than Delta. A strong and standard approach to compute arboricitydependent colorings is through the NashWilliams forest decomposition, which gives rise to an acyclic orientation of the edges such that each node has a small outdegree. Our main technical contribution is giving efficient deterministic algorithms to compute these orientations and showing how to leverage them to find colorings in lowspace AMPC. A key technical challenge is that the color of a node may depend on almost all of the other nodes in the graph and these dependencies cannot be stored on a single machine. Nevertheless, our novel and careful exploration technique yields the orientation, and the arboricitydependent coloring, with a sublinear number of adaptive queries per node.","Wed, 21 Feb 2024 12:33:34 UTC (451 KB)"
"35","ExaLogLog: Space-Efficient and Practical Approximate Distinct Counting up to the Exa-Scale","Otmar Ertl","Data Structures and Algorithms (cs.DS)","This work introduces ExaLogLog, a new data structure for approximate distinct counting, which has the same practical properties as the popular HyperLogLog algorithm. It is commutative, idempotent, mergeable, reducible, has a constanttime insert operation, and supports distinct counts up to the exascale. At the same time, as theoretically derived and experimentally verified, it requires 43 less space to achieve the same estimation error.","Wed, 21 Feb 2024 11:39:33 UTC (7,540 KB)"
"36","Towards Linear Spanners in All Temporal Cliques","Sebastian Angrick, Ben Bals, Tobias Friedrich, Hans Gawendowicz, Niko Hastrich, Nicolas Klodt, Pascal Lenzner, Jonas Schmidt, George Skretas, Armin Wells","Discrete Mathematics (cs.DM)","Many realworld networks, like transportation networks and social networks, are dynamic in the sense that the edge set may change over time, but these changes are known in advance. This behavior is captured by the temporal graphs model, which has recently become a trending topic in theoretical computer science. A core open problem in the field is to prove the existence of linearsize temporal spanners in temporal cliques, i.e., sparse subgraphs of complete temporal graphs that ensure allpairs reachability via temporal paths. So far, the best known result is the existence of temporal spanners with mathcalOnlog n many edges. We present significant progress towards proving that linearsize temporal spanners exist in all temporal cliques. We adapt techniques used in previous works and heavily expand and generalize them to provide a simpler and more intuitive proof of the mathcalOnlog n bound. Moreover, we use our novel approach to show that a large class of temporal cliques, called edgepivot graphs, admit linearsize temporal spanners. To contrast this, we investigate other classes of temporal cliques that do not belong to the class of edgepivot graphs. We introduce two such graph classes and we develop novel techniques for establishing the existence of linear temporal spanners in these graph classes as well.","Wed, 21 Feb 2024 08:53:04 UTC (453 KB)"
"37","A cutting plane algorithm for globally solving low dimensional k-means clustering problems","Martin Ryner, Jan Kronqvist, Johan Karlsson","Optimization and Control (math.OC)","Clustering is one of the most fundamental tools in data science and machine learning, and kmeans clustering is one of the most common such methods. There is a variety of approximate algorithms for the kmeans problem, but computing the globally optimal solution is in general NPhard. In this paper we consider the kmeans problem for instances with low dimensional data and formulate it as a structured concave assignment problem. This allows us to exploit the low dimensional structure and solve the problem to global optimality within reasonable time for large data sets with several clusters. The method builds on iteratively solving a small concave problem and a large linear programming problem. This gives a sequence of feasible solutions along with bounds which we show converges to zero optimality gap. The paper combines methods from global optimization theory to accelerate the procedure, and we provide numerical results on their performance.","Wed, 21 Feb 2024 07:55:33 UTC (63 KB)"
"38","Prediction of the Economic Behavior of Fishery Biotechnology Companies Based on Machine Learning-Based Deep Metacellular Automata","Liguo Chen, Hongyang Hua, Xinyue Luo, Guoli Xu, Xu Yan","Applications (stat.AP)","Ocean warming significantly affects the fishing industry, with species like Scottish herring and mackerel migrating northwards. Our research, a fusion of artificial intelligence, data science, and operations research, addresses this crisis. Using Long Short Term Memory networks, we forecast sea surface temperatures SST and model fish migratory patterns with Enhanced Cellular Automata. A corrective factor within our model adjusts for human impact on SST, guiding diverse mitigation scenarios. We apply operational research to strategize responses, including the modernization of fishing vessels as a less costly alternative to relocation. Our datadriven approach, suggesting fleet modernization, strategic relocation, and product diversification, offers an effective approach to mitigating the threats to the ocean warming phenomenon.","Wed, 21 Feb 2024 03:43:49 UTC (679 KB)[v2] Sat, 24 Feb 2024 07:12:00 UTC (735 KB)"
"39","Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit","Nur Yildirim, Susanna Zlotnikov, Deniz Sayar, Jeremy M. Kahn, Leigh A. Bukowski, Sher Shah Amin, Kathryn A. Riman, Billie S. Davis, John S. Minturn, Andrew J. King, Dan Ricketts, Lu Tang, Venkatesh Sivaraman, Adam Perer, Sarah M. Preum, James McCann, John Zimmerman","Human-Computer Interaction (cs.HC)","Advances in artificial intelligence AI have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.","Wed, 21 Feb 2024 00:11:13 UTC (8,166 KB)"
"40","Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing","Freda Shi, Kevin Gimpel, Karen Livescu","Computation and Language (cs.CL)","We present the structured average intersectionoverunion ratio STRUCTIOU, a similarity metric between constituency parse trees motivated by the problem of evaluating speech parsers. STRUCTIOU enables comparison between a constituency parse tree over automatically recognized spoken word boundaries with the groundtruth parse over written words. To compute the metric, we project the groundtruth parse tree to the speech domain by forced alignment, align the projected groundtruth constituents with the predicted ones under certain structured constraints, and calculate the average IOU score across all aligned constituent pairs. STRUCTIOU takes word boundaries into account and overcomes the challenge that the predicted words and ground truth may not have perfect onetoone correspondence. Extending to the evaluation of text constituency parsing, we demonstrate that STRUCTIOU shows higher tolerance to syntactically plausible parses than PARSEVAL Black et al., 1991.","Wed, 21 Feb 2024 00:01:17 UTC (6,835 KB)"
"41","Minimizing Tardy Processing Time on a Single Machine in Near-Linear Time","Nick Fischer, Leo Wennmann","Data Structures and Algorithms (cs.DS)","In this work we revisit the elementary scheduling problem 1sum pj Uj. The goal is to select, among n jobs with processing times and due dates, a subset of jobs with maximum total processing time that can be scheduled in sequence without violating their due dates. This problem is NPhard, but a classical algorithm by Lawler and Moore from the 60s solves this problem in pseudopolynomial time OnP, where P is the total processing time of all jobs. With the aim to develop bestpossible pseudopolynomialtime algorithms, a recent wave of results has improved Lawler and Moores algorithm for 1sum pj Uj First to time tilde OP74 Bringmann, Fischer, Hermelin, Shabtay, Wellnitz ICALP20, then to time tilde OP53 Klein, Polak, Rohwedder SODA23, and finally to time tilde OP75 Schieber, Sitaraman WADS23. It remained an exciting open question whether these works can be improved further. In this work we develop an algorithm in nearlinear time tilde OP for the 1sum pj Uj problem. This running time not only significantly improves upon the previous results, but also matches conditional lower bounds based on the Strong Exponential Time Hypothesis or the Set Cover Hypothesis and is therefore likely optimal up to subpolynomial factors. Our new algorithm also extends to the case of m machines in time tilde OPm. In contrast to the previous improvements, we take a different, more direct approach inspired by the recent reductions from Modular Subset Sum to dynamic string problems. We thereby arrive at a satisfyingly simple algorithm.","Tue, 20 Feb 2024 20:19:33 UTC (226 KB)"
"42","Online Matching on $3$-Uniform Hypergraphs","Sander Borst, Danish Kashaev, Zhuan Khye Koh","Data Structures and Algorithms (cs.DS)","The online matching problem was introduced by Karp, Vazirani and Vazirani STOC 1990 on bipartite graphs with vertex arrivals. It is wellknown that the optimal competitive ratio is 11e for both integral and fractional versions of the problem. Since then, there has been considerable effort to find optimal competitive ratios for other related settings. In this work, we go beyond the graph case and study the online matching problem on kuniform hypergraphs. For k3, we provide an optimal primaldual fractional algorithm, which achieves a competitive ratio of e1e1approx 0.4621. As our main technical contribution, we present a carefully constructed adversarial instance, which shows that this ratio is in fact optimal. It combines ideas from known hard instances for bipartite graphs under the edgearrival and vertexarrival models. For kgeq 3, we give a simple integral algorithm which performs better than greedy when the online nodes have bounded degree. As a corollary, it achieves the optimal competitive ratio of 12 on 3uniform hypergraphs when every online node has degree at most 2. This is because the special case where every online node has degree 1 is equivalent to the edgearrival model on graphs, for which an upper bound of 12 is known.","Tue, 20 Feb 2024 18:41:11 UTC (214 KB)"
"43","Testing Calibration in Subquadratic Time","Lunjia Hu, Kevin Tian, Chutong Yang","Machine Learning (cs.LG)","In the recent literature on machine learning and decision making, calibration has emerged as a desirable and widelystudied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less wellexplored. Motivated by BGHN23, which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of calibration testing from samples where given n draws from a distribution mathcalD on predictions, binary outcomes, our goal is to distinguish between the case where mathcalD is perfectly calibrated, and the case where mathcalD is varepsilonfar from calibration. We design an algorithm based on approximate linear programming, which solves calibration testing informationtheoretically optimally up to constant factors in time On1.5 logn. This improves upon stateoftheart blackbox linear program solvers requiring Omeganomega time, where omega  2 is the exponent of matrix multiplication. We also develop algorithms for tolerant variants of our testing problem, and give sample complexity lower bounds for alternative calibration distances to the one considered in this work. Finally, we present preliminary experiments showing that the testing problem we define faithfully captures standard notions of calibration, and that our algorithms scale to accommodate moderate sample sizes.","Tue, 20 Feb 2024 17:53:24 UTC (89 KB)"
"44","Improved Space Bounds for Subset Sum","Tatiana Belova, Nikolai Chukhin, Alexander S. Kulikov, Ivan Mihajlin","Computational Complexity (cs.CC)","More than 40 years ago, Schroeppel and Shamir presented an algorithm that solves the Subset Sum problem for n integers in time O20.5n and space O20.25n. The time upper bound remains unbeaten, but the space upper bound has been improved to O20.249999n in a recent breakthrough paper by Nederlof and Wgrzycki STOC 2021. Their algorithm is a clever combination of a number of previously known techniques with a new reduction and a new algorithm for the Orthogonal Vectors problem. In this paper, we give two new algorithms for Subset Sum. We start by presenting an ArthurMerlin algorithm upon receiving the verifiers randomness, the prover sends an n4bit long proof to the verifier who checks it in deterministic time and space O2n4. The simplicity of this algorithm has a number of interesting consequences it can be parallelized easily also, by enumerating all possible proofs, one recovers upper bounds on time and space for Subset Sum proved by Schroeppel and Shamir in 1979. As it is the case with the previously known algorithms for Subset Sum, our algorithm follows from an algorithm for 4SUM we prove that, using verifiers coin tosses, the prover can prepare a log2 nbit long proof verifiable in time tildeOn. Another interesting consequence of this result is the following finegrained lower bound assuming that 4SUM cannot be solved in time On2varepsilon for all varepsilon0, Circuit SAT cannot be solved in time Og21varepsilonn, for all varepsilon0. Then, we improve the space bound by Nederlof and Wgrzycki to O20.246n and also simplify their algorithm and its analysis. We achieve this space bound by further filtering sets of subsets using a random prime number. This allows us to reduce an instance of Subset Sum to a larger number of instances of smaller size.","Tue, 20 Feb 2024 17:30:45 UTC (27 KB)"
"45","Clustered Planarity Variants for Level Graphs","Simon D. Fink, Matthias Pfretzschner, Ignaz Rutter, Marie Diana Sieper","Computational Geometry (cs.CG)","We consider variants of the clustered planarity problem for levelplanar drawings. So far, only convex clusters have been studied in this setting. We introduce two new variants that both insist on a levelplanar drawing of the input graph but relax the requirements on the shape of the clusters. In unrestricted Clustered Level Planarity uCLP we only require that they are bounded by simple closed curves that enclose exactly the vertices of the cluster and cross each edge of the graph at most once. The problem ymonotone Clustered Level Planarity yCLP requires that additionally it must be possible to augment each cluster with edges that do not cross the cluster boundaries so that it becomes connected while the graph remains levelplanar, thereby mimicking a classic characterization of clustered planarity in the levelplanar setting. We give a polynomialtime algorithm for uCLP if the input graph is biconnected and has a single source. By contrast, we show that yCLP is hard under the same restrictions and it remains NPhard even if the number of levels is bounded by a constant and there is only a single nontrivial cluster.","Tue, 20 Feb 2024 17:10:42 UTC (429 KB)"
"46","Almost-Tight Bounds on Preserving Cuts in Classes of Submodular Hypergraphs","Sanjeev Khanna, Aaron L. Putterman, Madhu Sudan","Data Structures and Algorithms (cs.DS)","Recently, a number of variants of the notion of cutpreserving hypergraph sparsification have been studied in the literature. These variants include directed hypergraph sparsification, submodular hypergraph sparsification, general notions of approximation including spectral approximations, and more general notions like sketching that can answer cut queries using more general data structures than just sparsifiers. In this work, we provide reductions between these different variants of hypergraph sparsification and establish new upper and lower bounds on the space complexity of preserving their cuts. At a high level, our results use the same general principle, namely, by showing that cuts in one class of hypergraphs can be simulated by cuts in a simpler class of hypergraphs, we can leverage sparsification results for the simpler class of hypergraphs.","Tue, 20 Feb 2024 17:06:47 UTC (29 KB)"
"47","Deterministic Dynamic Edge-Colouring","Aleksander B. G. Christiansen","Data Structures and Algorithms (cs.DS)","Given a dynamic graph G with n vertices and m edges subject to insertion an deletions of edges, we show how to maintain a 1varepsilonDeltaedgecolouring of G without the use of randomisation. More specifically, we show a deterministic dynamic algorithm with an amortised update time of 2tildeOlog varepsilon1sqrtlog n using 1varepsilonDelta colours. If varepsilon1 in 2Olog0.49 n, then our update time is subpolynomial in n. While there exists randomised algorithms maintaining colourings with the same number of colours Christiansen STOC23, Duan, He, Zhang SODA19, Bhattacarya, Costa, Panski, Solomon SODA24 in polylogarithmic and even constant update time, this is the first deterministic algorithm to go below the greedy threshold of 2Delta1 colours for all input graphs. On the way to our main result, we show how to dynamically maintain a shallow hierarchy of degreesplitters with both recourse and update time in no1. We believe that this algorithm might be of independent interest.","Tue, 20 Feb 2024 16:54:43 UTC (642 KB)"
"48","Scalable Pattern Matching in Computation Graphs","Luca Mondada, Pablo Andrés-Martínez","Data Structures and Algorithms (cs.DS)","Graph rewriting is a popular tool for the optimisation and modification of graph expressions in domains such as compilers, machine learning and quantum computing. The underlying data structures are often port graphs  graphs with labels at edge endpoints. These port labels greatly simplify pattern matching. A prerequisite for graph rewriting is the ability to find subgraphs of the input that match known graph identities the pattern matching problem. We propose a new solution to pattern matching in port graphs. Its novelty lies in the use of a precomputed data structure that makes the pattern matching runtime complexity independent of the number of patterns. The runtime is bound by the maximum width w and depth d of the patterns, as well as the input graph size G as OG cdot cw  w12 cdot d with c  6.75. This offers a significant advantage over existing solutions for use cases where patterns have low width and the set of patterns is large and fixed ahead of time. In the context of quantum circuits, pattern width can be limited to qubit number. Quantum superoptimisers may use thousands of rewrite rules on circuits with less than 5 qubits, making them an ideal use case. We provide benchmarks showing that our algorithm offers a 20x speedup over current implementations on a dataset of 10000 real world patterns describing quantum circuits.","Tue, 20 Feb 2024 15:02:24 UTC (113 KB)"
"49","Efficient Enumeration of Large Maximal k-Plexes","Qihao Cheng, Da Yan, Tianhao Wu, Lyuheng Yuan, Ji Cheng, Zhongyi Huang, Yang Zhou","Data Structures and Algorithms (cs.DS)","Finding cohesive subgraphs in a large graph has many important applications, such as community detection and biological network analysis. Clique is often a too strict cohesive structure since communities or biological modules rarely form as cliques for various reasons such as data noise. Therefore, kplex is introduced as a popular clique relaxation, which is a graph where every vertex is adjacent to all but at most k vertices. In this paper, we propose an efficient branchandbound algorithm as well as its taskbased parallel version to enumerate all maximal kplexes with at least q vertices. Our algorithm adopts an effective search space partitioning approach that provides a good time complexity, a new pivot vertex selection method that reduces candidate vertex size, an effective upperbounding technique to prune useless branches, and three novel pruning techniques by vertex pairs. Our parallel algorithm uses a timeout mechanism to eliminate straggler tasks, and maximizes cache locality while ensuring load balancing. Extensive experiments show that compared with the stateoftheart algorithms, our sequential and parallel algorithms enumerate large maximal kplexes with up to 5 times and 18.9 times speedup, respectively. Ablation results also demonstrate that our pruning techniques bring up to 7 times speedup compared with our basic algorithm.","Tue, 20 Feb 2024 13:43:16 UTC (680 KB)"
"50","Locally Rainbow Paths","Till Fluschnik, Leon Kellerhals, Malte Renken","Data Structures and Algorithms (cs.DS)","We introduce the algorithmic problem of finding a locally rainbow path of length ell connecting two distinguished vertices s and t in a vertexcolored directed graph. Herein, a path is locally rainbow if between any two visits of equally colored vertices, the path traverses consecutively at least r differently colored vertices. This problem generalizes the wellknown problem of finding a rainbow path. It finds natural applications whenever there are different types of resources that must be protected from overuse, such as crop sequence optimization or production process scheduling. We show that the problem is computationally intractable even if r2 or if one looks for a locally rainbow among the shortest paths. On the positive side, if one looks for a path that takes only a short detour i.e., it is slightly longer than the shortest path and if r is small, the problem can be solved efficiently. Indeed, the running time of the respective algorithm is nearoptimal unless the ETH fails.","Tue, 20 Feb 2024 10:50:01 UTC (45 KB)"
"51","Differentiable Mapper For Topological Optimization Of Data Representation","Ziyad Oulhaj, Mathieu Carrière, Bertrand Michel","Machine Learning (cs.LG)","Unsupervised data representation and visualization using tools from topology is an active and growing field of Topological Data Analysis TDA and data science. Its most prominent line of work is based on the socalled Mapper graph, which is a combinatorial graph whose topological structures connected components, branches, loops are in correspondence with those of the data itself. While highly generic and applicable, its use has been hampered so far by the manual tuning of its many parametersamong these, a crucial one is the socalled filter it is a continuous function whose variations on the data set are the main ingredient for both building the Mapper representation and assessing the presence and sizes of its topological structures. However, while a few parameter tuning methods have already been investigated for the other Mapper parameters i.e., resolution, gain, clustering, there is currently no method for tuning the filter itself. In this work, we build on a recently proposed optimization framework incorporating topology to provide the first filter optimization scheme for Mapper graphs. In order to achieve this, we propose a relaxed and more general version of the Mapper graph, whose convergence properties are investigated. Finally, we demonstrate the usefulness of our approach by optimizing Mapper graph representations on several datasets, and showcasing the superiority of the optimized representation over arbitrary ones.","Tue, 20 Feb 2024 09:33:22 UTC (2,650 KB)"
"52","Nearly Optimal Fault Tolerant Distance Oracle","Dipan Dey, Manoj Gupta","Data Structures and Algorithms (cs.DS)","We present an ffault tolerant distance oracle for an undirected weighted graph where each edge has an integral weight from 1 dots W. Given a set F of f edges, as well as a source node s and a destination node t, our oracle returns the emphshortest path from s to t avoiding F in Ocf log nWOf2 time, where c  1 is a constant. The space complexity of our oracle is Of4n2log2 nW. For a constant f, our oracle is nearly optimal both in terms of space and time barring some logarithmic factor.","Tue, 20 Feb 2024 08:58:37 UTC (85 KB)[v2] Wed, 21 Feb 2024 10:24:10 UTC (96 KB)"
"53","Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss","Hao Wang, Chenyi Zhang, Tongyang Li","Quantum Physics (quant-ph)","The problem of minimizing the maximum of N convex, Lipschitz functions plays significant roles in optimization and machine learning. It has a series of results, with the most recent one requiring ONepsilon23  epsilon83 queries to a firstorder oracle to compute an epsilonsuboptimal point. On the other hand, quantum algorithms for optimization are rapidly advancing with speedups shown on many important optimization problems. In this paper, we conduct a systematic study for quantum algorithms and lower bounds for minimizing the maximum of N convex, Lipschitz functions. On one hand, we develop quantum algorithms with an improved complexity bound of tildeOsqrtNepsilon53  epsilon83. On the other hand, we prove that quantum algorithms must take tildeOmegasqrtNepsilon23 queries to a first order quantum oracle, showing that our dependence on N is optimal up to polylogarithmic factors.","Tue, 20 Feb 2024 06:23:36 UTC (62 KB)"
"54","A Lower Bound on the Competitive Ratio of the Permutation Algorithm for Online Facility Assignment on a Line","Tsubasa Harada","Data Structures and Algorithms (cs.DS)","In the online facility assignment on a line OFAL with a set S of k servers and a capacity cStomathbbN, each server sin S with a capacity cs is placed on a line and a request arrives on a line onebyone. The task of an online algorithm is to irrevocably assign a current request to one of the servers with vacancies before the next request arrives. An algorithm can assign up to cs requests to each server sin S. In this paper, we show that the competitive ratio of the permutation algorithm is at least k1 for OFAL where the servers are evenly placed on a line. This disproves the result that the permutation algorithm is kcompetitive by Ahmed et al..","Tue, 20 Feb 2024 05:59:10 UTC (8 KB)[v2] Fri, 23 Feb 2024 01:44:37 UTC (8 KB)"
"55","Controlled Variable Selection from Summary Statistics Only? A Solution via GhostKnockoffs and Penalized Regression","Zhaomeng Chen, Zihuai He, Benjamin B. Chu, Jiaqi Gu, Tim Morrison, Chiara Sabatti, Emmanuel Candès","Methodology (stat.ME)","Identifying which variables do influence a response while controlling false positives pervades statistics and data science. In this paper, we consider a scenario in which we only have access to summary statistics, such as the values of marginal empirical correlations between each dependent variable of potential interest and the response. This situation may arise due to privacy concerns, e.g., to avoid the release of sensitive genetic information. We extend GhostKnockoffs He et al. 2022 and introduce variable selection methods based on penalized regression achieving false discovery rate FDR control. We report empirical results in extensive simulation studies, demonstrating enhanced performance over previous work. We also apply our methods to genomewide association studies of Alzheimers disease, and evidence a significant improvement in power.","Tue, 20 Feb 2024 05:16:24 UTC (6,378 KB)"
"56","Distance Recoloring","Niranka Banerjee, Christian Engels, Duc A. Hoang","Data Structures and Algorithms (cs.DS)","Coloring a graph is a well known problem and used in many different contexts. Here we want to assign k geq 1 colors to each vertex of a graph G such that each edge has two different colors at each endpoint. Such a vertexcoloring, if exists, is called a feasible coloring of G. textscDistance Coloring is an extension to the standard textscColoring problem. Here we want to enforce that every pair of distinct vertices of distance less than or equal to d have different colors, for integers d geq 1 and k geq d1. Reconfiguration problems ask if two given configurations can be transformed into each other with certain rules. For example, the wellknown textscColoring Reconfiguration asks if there is a way to change one vertexs color at a time, starting from a feasible given coloring alpha of a graph G to reach another feasible given coloring beta of G, such that all intermediate colorings are also feasible. In this paper, we study the reconfiguration of distance colorings on certain graph classes. We show that even for planar, bipartite, and 2degenerate graphs, reconfiguring distance colorings is mathsfPSPACEcomplete for d geq 2 and k  Omegad2 via a reduction from the wellknown textscSliding Tokens problem. Additionally, we show that the problem on split graphs remains mathsfPSPACEcomplete when d  2 and large k but can be solved in polynomial time when d geq 3 and k geq d1, and design a quadratictime algorithm to solve the problem on paths for any d geq 2 and k geq d1.","Tue, 20 Feb 2024 04:09:00 UTC (40 KB)"
"57","Optimal PSPACE-hardness of Approximating Set Cover Reconfiguration","Shuichi Hirahara, Naoto Ohsaka","Computational Complexity (cs.CC)","In the Minmax Set Cover Reconfiguration problem, given a set system mathcalF over a universe and its two covers mathcalCmathsfstart and mathcalCmathsfgoal of size k, we wish to transform mathcalCmathsfstart into mathcalCmathsfgoal by repeatedly adding or removing a single set of mathcalF while covering the universe in any intermediate state. Then, the objective is to minimize the maximize size of any intermediate cover during transformation. We prove that Minmax Set Cover Reconfiguration and Minmax Dominating Set Reconfiguration are mathsfPSPACEhard to approximate within a factor of 2frac1operatornamepolyloglog N, where N is the size of the universe and the number of vertices in a graph, respectively, improving upon Ohsaka SODA 2024 and Karthik C. S. and Manurangsi 2023. This is the first result that exhibits a sharp threshold for the approximation factor of any reconfiguration problem because both problems admit a 2factor approximation algorithm as per Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno Theor. Comput. Sci., 2011. Our proof is based on a reconfiguration analogue of the FGLSS reduction from Probabilistically Checkable Reconfiguration Proofs of Hirahara and Ohsaka 2024. We also prove that for any constant varepsilon in 0,1, Minmax Hypergraph Vertex Cover Reconfiguration on operatornamepolyvarepsilon1uniform hypergraphs is mathsfPSPACEhard to approximate within a factor of 2varepsilon.","Tue, 20 Feb 2024 01:46:30 UTC (29 KB)"
"58","Guarantees on Warm-Started QAOA: Single-Round Approximation Ratios for 3-Regular MAXCUT and Higher-Round Scaling Limits","Reuben Tate, Stephan Eidenbenz","Quantum Physics (quant-ph)","We generalize Farhi et al.s 0.6924approximation result technique of the MaxCut Quantum Approximate Optimization Algorithm QAOA on 3regular graphs to obtain provable lower bounds on the approximation ratio for warmstarted QAOA. Given an initialization angle theta, we consider warmstarts where the initial state is a product state where each qubit position is angle theta away from either the north or south pole of the Bloch sphere of the two possible qubit positions the position of each qubit is decided by some classically obtained cut encoded as a bitstring b. We illustrate through plots how the properties of b and the initialization angle theta influence the bound on the approximation ratios of warmstarted QAOA. We consider various classical algorithms and the cuts they produce which we use to generate the warmstart. Our results strongly suggest that there does not exist any choice of initialization angle that yields a worstcase approximation ratio that simultaneously beats standard QAOA and the classical algorithm used to create the warmstart. Additionally, we show that at theta60circ, warmstarted QAOA is able to effectively recover the cut used to generate the warmstart, thus suggesting that in practice, this value could be a promising starting angle to explore alternate solutions in a heuristic fashion. Finally, for any combinatorial optimization problem with integervalued objective values, we provide bounds on the required circuit depth needed for warmstarted QAOA to achieve some change in approximation ratio more specifically, we show that for small theta, the bound is roughly proportional to 1theta.","Tue, 20 Feb 2024 01:22:07 UTC (2,270 KB)"
"59","Lettericity of graphs: an FPT algorithm and a bound on the size of obstructions","Bogdan Alecu, Mamadou Moustapha Kanté, Vadim Lozin, Viktor Zamaraev","Combinatorics (math.CO)","Lettericity is a graph parameter responsible for many attractive structural properties. In particular, graphs of bounded lettericity have bounded linear cliquewidth and they are wellquasiordered by induced subgraphs. The latter property implies that any hereditary class of graphs of bounded lettericity can be described by finitely many forbidden induced subgraphs. This, in turn, implies, in a nonconstructive way, polynomialtime recognition of such classes. However, no constructive algorithms and no specific bounds on the size of forbidden graphs are available up to date. In the present paper, we develop an algorithm that recognizes nvertex graphs of lettericity at most k in time fkn3 and show that any minimal graph of lettericity more than k has at most 2Ok2log k vertices.","Mon, 19 Feb 2024 21:33:01 UTC (27 KB)"
"60","Almost-linear time parameterized algorithm for rankwidth via dynamic rankwidth","Tuukka Korhonen, Marek Sokołowski","Data Structures and Algorithms (cs.DS)","We give an algorithm that given a graph G with n vertices and m edges and an integer k, in time Okn1o1  Om either outputs a rank decomposition of G of width at most k or determines that the rankwidth of G is larger than k the Okcdotnotation hides factors depending on k. Our algorithm returns also a 2k11expression for cliquewidth, yielding a 2k11approximation algorithm for cliquewidth with the same running time. This improves upon the Okn2 time algorithm of Fomin and Korhonen STOC 2022. The main ingredient of our algorithm is a fully dynamic algorithm for maintaining rank decompositions of bounded width We give a data structure that for a dynamic nvertex graph G that is updated by edge insertions and deletions maintains a rank decomposition of G of width at most 4k under the promise that the rankwidth of G never grows above k. The amortized running time of each update is Ok2sqrtlog n log log n. The data structure furthermore can maintain whether G satisfies some fixed sf CMSO1 property within the same running time. We also give a framework for performing dense edge updates inside a given set of vertices X, where the new edges inside X are described by a given sf CMSO1 sentence and vertex labels, in amortized OkX cdot 2sqrtlog n log log n time. Our dynamic algorithm generalizes the dynamic treewidth algorithm of Korhonen, Majewski, Nadara, Pilipczuk, and Sokoowski FOCS 2023.","Mon, 19 Feb 2024 18:50:53 UTC (489 KB)"
"61","Local certification of forbidden subgraphs","Nicolas Bousquet, Linda Cook, Laurent Feuilloley, Théo Pierron, Sébastien Zeitoun","Distributed, Parallel, and Cluster Computing (cs.DC)","Detecting specific structures in a network has been a very active theme of research in distributed computing for at least a decade. In this paper, we start the study of subgraph detection from the perspective of local certification. Remember that a local certification is a distributed mechanism enabling the nodes of a network to check the correctness of the current configuration, thanks to small pieces of information called certificates. Our main question is For a given graph H, what is the minimum certificate size that allows checking that the network does not contain H as a possibly induced subgraph? We show a variety of lower and upper bounds, uncovering an interesting interplay between the optimal certificate size, the size of the forbidden subgraph, and the locality of the verification. Along the way we introduce several new technical tools, in particular what we call the emphlayered map, which is not specific to forbidden subgraphs and that we expect to be useful for certifying many other properties.","Mon, 19 Feb 2024 14:01:34 UTC (128 KB)"
"62","Connectivity Labeling in Faulty Colored Graphs","Asaf Petruschka, Shay Sapir, Elad Tzalik","Data Structures and Algorithms (cs.DS)","Faulttolerant connectivity labelings are schemes that, given an nvertex graph GV,E and fgeq 1, produce succinct yet informative labels for the elements of the graph. Given only the labels of two vertices u,v and of the elements in a faultyset F with Fleq f, one can determine if u,v are connected in GF, the surviving graph after removing F. For the edge or vertex faults models, i.e., Fsubseteq E or Fsubseteq V, a sequence of recent work established schemes with polyf,log nbit labels. This paper considers the color faults model, recently introduced in the context of spanners Petruschka, Sapir and Tzalik, ITCS24, which accounts for known correlations between failures. Here, the edges or vertices of the input G are arbitrarily colored, and the faulty elements in F are colors a failing color causes all edges vertices of that color to crash. Our main contribution is settling the label length complexity for connectivity under one color fault f1. The existing implicit solution, by applying the stateoftheart scheme for edge faults of Dory and Parter, PODC21, might yield labels of Omegan bits. We provide a deterministic scheme with labels of tildeOsqrtn bits in the worst case, and a matching lower bound. Moreover, our scheme is universally optimal even schemes tailored to handle only colorings of one specific graph topology cannot produce asymptotically smaller labels. We extend our labeling approach to yield a routing scheme avoiding a single forbidden color. We also consider the centralized setting, and show an tildeOnspace oracle, answering connectivity queries under one color fault in tildeO1 time. Turning to fgeq 2 color faults, we give a randomized labeling scheme with tildeOn112fbit labels, along with a lower bound of Omegan11f1 bits.","Mon, 19 Feb 2024 13:53:13 UTC (362 KB)"
"63","The Complexity of Geodesic Spanners using Steiner Points","Sarita de Berg, Tim Ophelders, Irene Parada, Frank Staals, Jules Wulms","Computational Geometry (cs.CG)","A geometric tspanner mathcalG on a set S of n point sites in a metric space P is a subgraph of the complete graph on S such that for every pair of sites p,q the distance in mathcalG is a most t times the distance dp,q in P. We call a connection between two sites in the spanner a link. In some settings, such as when P is a simple polygon with m vertices and a link is a shortest path in P, links can consist of Theta m segments and thus have nonconstant complexity. The total spanner complexity is a recentlyintroduced measure of how compact a spanner is. In this paper, we study what happens if we are allowed to introduce k Steiner points to reduce the spanner complexity. We study such Steiner spanners in simple polygons, polygonal domains, and edgeweighted trees. Surprisingly, we show that Steiner points have only limited utility. For a spanner that uses k Steiner points, we provide an Omeganmk lower bound on the worstcase complexity of any 3varepsilonspanner, and an Omegamn1t1k1t1 lower bound on the worstcase complexity of any tvarepsilonspanner, for any constant varepsilonin 0,1 and integer constant t geq 2. These lower bounds hold in all settings. Additionally, we show NPhardness for the problem of deciding whether a set of sites in a polygonal domain admits a 3spanner with a given maximum complexity using k Steiner points. On the positive side, for trees we show how to build a 2tspanner that uses k Steiner points and of complexity Omn1tk1t  n log nk, for any integer t geq 1. We generalize this result to forests, and apply it to obtain a 2sqrt2tspanner in a simple polygon or a 6tspanner in a polygonal domain, with total complexity Omn1tlog k11tk1t  nlog2 n.","Mon, 19 Feb 2024 13:01:46 UTC (872 KB)"
"64","Causal Equal Protection as Algorithmic Fairness","Marcello Di Bello, Nicolò Cangiotti, Michele Loi","Computers and Society (cs.CY)","Over the last ten years the literature in computer science and philosophy has formulated different criteria of algorithmic fairness. One of the most discussed, classification parity, requires that the erroneous classifications of a predictive algorithm occur with equal frequency for groups picked out by protected characteristics. Despite its intuitive appeal, classification parity has come under attack. Multiple scenarios can be imagined in which  intuitively  a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated. To make progress, we turn to a related principle, equal protection, originally developed in the context of criminal justice. Key to equal protection is equalizing the risks of erroneous classifications in a sense to be specified as opposed to equalizing the rates of erroneous classifications. We show that equal protection avoids many of the counterexamples to classification parity, but also fails to model our moral intuitions in a number of common scenarios, for example, when the predictor is causally downstream relative to the protected characteristic. To address these difficulties, we defend a novel principle, causal equal protection, that models the fair allocation of the risks of erroneous classification through the lenses of causality.","Mon, 19 Feb 2024 11:30:00 UTC (231 KB)[v2] Tue, 20 Feb 2024 22:53:23 UTC (231 KB)"
"65","Collision-Free Robot Scheduling","Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul Spirakis","Data Structures and Algorithms (cs.DS)","Robots are becoming an increasingly common part of scientific work within laboratory environments. In this paper, we investigate the problem of designing emphschedules for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph allowing for a robot to wait at a vertex to complete a task, with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules. We show that this problem is NPcomplete for many simple classes of graphs, the problem of determining the fastest schedule, defined by the number of time steps required for a robot to visit every vertex in the schedule and complete every task assigned in its assigned schedule. Explicitly, we provide this result for complete graphs, bipartite graphs, star graphs, and planar graphs. Finally, we provide positive results for line graphs, showing that we can find an optimal set of schedules for k robots completing m tasks of equal length of a path of length n in Okmn time, and a kapproximation when the length of the tasks is unbounded.","Mon, 19 Feb 2024 10:28:34 UTC (232 KB)"
"66","Private Interdependent Valuations: New Bounds for Single-Item Auctions and Matroids","Alon Eden, Michal Feldman, Simon Mauras, Divyarthi Mohan","Computer Science and Game Theory (cs.GT)","We study auction design within the widely acclaimed model of interdependent values, introduced by Milgrom and Weber 1982. In this model, every bidder i has a private signal si for the item for sale, and a public valuation function vis1,ldots,sn which maps every vector of private signals of all bidders into a real value. A recent line of work established the existence of approximatelyoptimal mechanisms within this framework, even in the more challenging scenario where each bidders valuation function vi is also private. This body of work has primarily focused on singleitem auctions with two natural classes of valuations those exhibiting submodularity over signals SOS and dcritical valuations. In this work we advance the state of the art on interdependent values with private valuation functions, with respect to both SOS and dcritical valuations. For SOS valuations, we devise a new mechanism that gives an improved approximation bound of 5 for singleitem auctions. This mechanism employs a novel variant of an eating mechanism, leveraging LPduality to achieve feasibility with reduced welfare loss. For dcritical valuations, we broaden the scope of existing results beyond singleitem auctions, introducing a mechanism that gives a d1approximation for any environment with matroid feasibility constraints on the set of agents that can be simultaneously served. Notably, this approximation bound is tight, even with respect to singleitem auctions.","Mon, 19 Feb 2024 10:20:21 UTC (27 KB)"
"67","Buffered Streaming Edge Partitioning","Adil Chhabra, Marcelo Fonseca Faraj, Christian Schulz, Daniel Seemaier","Data Structures and Algorithms (cs.DS)","Addressing the challenges of processing massive graphs, which are prevalent in diverse fields such as social, biological, and technical networks, we introduce HeiStreamE and FreightE, two innovative buffered streaming algorithms designed for efficient edge partitioning of largescale graphs. HeiStreamE utilizes an adapted SplitandConnect graph model and a Fennelbased multilevel partitioning scheme, while FreightE partitions a hypergraph representation of the input graph. Besides ensuring superior solution quality, these approaches also overcome the limitations of existing algorithms by maintaining linear dependency on the graph size in both time and memory complexity with no dependence on the number of blocks of partition. Our comprehensive experimental analysis demonstrates that HeiStreamE outperforms current streaming algorithms and the restreaming algorithm 2PS in partitioning quality replication factor, and is more memoryefficient for realworld networks where the number of edges is far greater than the number of vertices. Further, FreightE is shown to produce fast and efficient partitions, particularly for higher numbers of partition blocks.","Mon, 19 Feb 2024 09:26:22 UTC (384 KB)"
"68","To Store or Not to Store: a graph theoretical approach for Dataset Versioning","Anxin Guo, Jingwei Li, Pattara Sukprasert, Samir Khuller, Amol Deshpande, Koyel Mukherjee","Data Structures and Algorithms (cs.DS)","In this work, we study the cost efficient data versioning problem, where the goal is to optimize the storage and reconstruction retrieval costs of data versions, given a graph of datasets as nodes and edges capturing editdelta information. One central variant we study is MinSum Retrieval MSR where the goal is to minimize the total retrieval costs, while keeping the storage costs bounded. This problem along with its variants was introduced by Bhattacherjee et al. VLDB15. While such problems are frequently encountered in collaborative tools e.g., version control systems and data analysis pipelines, to the best of our knowledge, no existing research studies the theoretical aspects of these problems. We establish that the currently bestknown heuristic, LMG, can perform arbitrarily badly in a simple worst case. Moreover, we show that it is hard to get onapproximation for MSR on general graphs even if we relax the storage constraints by an Olog n factor. Similar hardness results are shown for other variants. Meanwhile, we propose polytime approximation schemes for treelike graphs, motivated by the fact that the graphs arising in practice from typical edit operations are often not arbitrary. As version graphs typically have low treewidth, we further develop new algorithms for bounded treewidth graphs. Furthermore, we propose two new heuristics and evaluate them empirically. First, we extend LMG by considering more potential moves, to propose a new heuristic LMGAll. LMGAll consistently outperforms LMG while having comparable run time on a wide variety of datasets, i.e., version graphs. Secondly, we apply our tree algorithms on the minimumstorage arborescence of an instance, yielding algorithms that are qualitatively better than all previous heuristics for MSR, as well as for another variant BoundedMin Retrieval BMR.","Sun, 18 Feb 2024 23:57:03 UTC (1,560 KB)"
"69","Faster algorithms on linear delta-matroids","Tomohiro Koana, Magnus Wahlström","Data Structures and Algorithms (cs.DS)","We show new algorithms and constructions over linear deltamatroids. We observe an alternative representation for linear deltamatroids, as a contraction representation over a skewsymmetric matrix. This is equivalent to the more standard twist representation up to Onomegatime transformations, but is much more convenient for algorithmic tasks. For instance, the problem of finding a maxweight feasible set now reduces directly to the problem of finding a maxweight basis in a linear matroid. Supported by this representation, we provide new algorithms and constructions over linear deltamatroids. We show that the union and deltasum of linear deltamatroids define linear deltamatroids, and a representation for the resulting deltamatroid can be constructed in randomized time Onomega. Previously, it was only known that these operations define deltamatroids. We also note that every projected linear deltamatroid can be represented as an elementary projection. This implies that several optimization problems over projected linear deltamatroids, including the coverage, deltacoverage, and parity problems, reduce in their decision versions to a single Onomegatime matrix rank computation. Using the methods of Harvey, previously used by Cheung, Lao and Leung for linear matroid parity, we furthermore show how to solve the search versions in the same time. This improves on the On4time augmenting path algorithm of Geelen, Iwata and Murota. Finally, we consider the maximumcardinality deltamatroid intersection problem. Using Storjohanns algorithms for symbolic determinants, we show that such a solution can be found in Onomega1 time. This is the first polynomialtime algorithm for the problem, solving an open question of Kakimura and Takamatsu.","Sun, 18 Feb 2024 14:17:30 UTC (49 KB)"
"70","Odd Cycle Transversal on $P_5$-free Graphs in Polynomial Time","Akanksha Agrawal, Paloma T. Lima, Daniel Lokshtanov, Pawel Rzążewski, Saket Saurabh, Roohani Sharma","Data Structures and Algorithms (cs.DS)","An independent set in a graph G is a set of pairwise nonadjacent vertices. A graph G is bipartite if its vertex set can be partitioned into two independent sets. In the Odd Cycle Transversal problem, the input is a graph G along with a weight function w associating a rational weight with each vertex, and the task is to find a smallest weight vertex subset S in G such that G  S is bipartite the weight of S, wS  sumvin S wv. We show that Odd Cycle Transversal is polynomialtime solvable on graphs excluding P5 a path on five vertices as an induced subgraph. The problem was previously known to be polynomialtime solvable on P4free graphs and NPhard on P6free graphs Dabrowski, Feghali, Johnson, Paesani, Paulusma and Rzewski, Algorithmica 2020. Bonamy, Dabrowski, Feghali, Johnson and Paulusma Algorithmica 2019 posed the existence of a polynomialtime algorithm on P5free graphs as an open problem, this was later restated by Rzewski Dagstuhl Reports, 96 2019 and by Chudnovsky, King, Pilipczuk, Rzewski, and Spirkl SIDMA 2021, who gave an algorithm with running time nOsqrtn.","Sun, 18 Feb 2024 05:42:53 UTC (1,262 KB)"
"71","A Simple Proof that Ricochet Robots is PSPACE-Complete","Jose Balanza-Martinez, Angel A. Cantu, Robert Schweller, Tim Wylie","Computational Complexity (cs.CC)","In this paper, we seek to provide a simpler proof that the relocation problem in Ricochet Robots Lunar Lockout with fixed geometry is PSPACEcomplete via a reduction from Finite Function Generation FFG. Although this result was originally proven in 2003, we give a simpler reduction by utilizing the FFG problem, and put the result in context with recent publications showing that relocation is also PSPACEcomplete in related models.","Sun, 18 Feb 2024 03:34:44 UTC (732 KB)"
"72","Approximating Partition in Near-Linear Time","Lin Chen, Jiayi Lian, Yuchen Mao, Guochuan Zhang","Data Structures and Algorithms (cs.DS)","We propose an widetildeOn  1varepsilontime FPTAS Fully PolynomialTime Approximation Scheme for the classical Partition problem. This is the best possible up to a logarithmic factor assuming SETH Strong Exponential Time Hypothesis Abboud, Bringmann, Hermelin, and Shabtay22. Prior to our work, the best known FPTAS for Partition runs in widetildeOn  1varepsilon54 time Deng, Jin and Mao23, Wu and Chen22. Our result is obtained by solving a more general problem of weakly approximating Subset Sum.","Sun, 18 Feb 2024 02:18:14 UTC (27 KB)"
"73","An Elementary Predictor Obtaining $2\sqrt{T}$ Distance to Calibration","Eshwar Ram Arunachaleswaran, Natalie Collina, Aaron Roth, Mirah Shi","Machine Learning (cs.LG)","Blasiok et al. 2023 proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error ECE is continuous. Recently, Qiao and Zheng 2024 gave a nonconstructive argument establishing the existence of an online predictor that can obtain OsqrtT distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most 2sqrtT.","Sun, 18 Feb 2024 00:53:05 UTC (295 KB)"
"74","Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search","Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa","Machine Learning (cs.LG)","Approximate nearest neighbor search ANNS in highdimensional spaces is a pivotal challenge in the field of machine learning. In recent years, graphbased methods have emerged as the superior approach to ANNS, establishing a new state of the art. Although various optimizations for graphbased ANNS have been introduced, they predominantly rely on heuristic methods that lack formal theoretical backing. This paper aims to enhance routing within graphbased ANNS by introducing a method that offers a probabilistic guarantee when exploring a nodes neighbors in the graph. We formulate the problem as probabilistic routing and develop two baseline strategies by incorporating localitysensitive techniques. Subsequently, we introduce PEOs, a novel approach that efficiently identifies which neighbors in the graph should be considered for exact distance computation, thus significantly improving efficiency in practice. Our experiments demonstrate that equipping PEOs can increase throughput on a commonly utilized graph index HNSW by a factor of 1.6 to 2.5, and its efficiency consistently outperforms the leadingedge routing technique by 1.1 to 1.4 times.","Sat, 17 Feb 2024 18:08:37 UTC (308 KB)"
"75","Treewidth versus clique number. IV. Tree-independence number of graphs excluding an induced star","Clément Dallard, Matjaž Krnc, O-joung Kwon, Martin Milanič, Andrea Munaro, Kenny Štorgel, Sebastian Wiederrecht","Combinatorics (math.CO)","Many recent works address the question of characterizing induced obstructions to bounded treewidth. In 2022, Lozin and Razgon completely answered this question for graph classes defined by finitely many forbidden induced subgraphs. Their result also implies a characterization of graph classes defined by finitely many forbidden induced subgraphs that are tw,omegabounded, that is, treewidth can only be large due to the presence of a large clique. This condition is known to be satisfied for any graph class with bounded treeindependence number, a graph parameter introduced independently by Yolov in 2018 and by Dallard, Milani, and torgel in 2024. Dallard et al. conjectured that tw,omegaboundedness is actually equivalent to bounded treeindependence number. We address this conjecture in the context of graph classes defined by finitely many forbidden induced subgraphs and prove it for the case of graph classes excluding an induced star. We also prove it for subclasses of the class of line graphs, determine the exact values of the treeindependence numbers of line graphs of complete graphs and line graphs of complete bipartite graphs, and characterize the treeindependence number of P4free graphs, which implies a lineartime algorithm for its computation. Applying the algorithmic framework provided in a previous paper of the series leads to polynomialtime algorithms for the Maximum Weight Independent Set problem in an infinite family of graph classes.","Sat, 17 Feb 2024 08:38:58 UTC (33 KB)[v2] Tue, 20 Feb 2024 14:55:58 UTC (33 KB)"
"76","Private PAC Learning May be Harder than Online Learning","Mark Bun, Aloni Cohen, Rathin Desai","Machine Learning (cs.LG)","We continue the study of the computational complexity of differentially private PAC learning and how it is situated within the foundations of machine learning. A recent line of work uncovered a qualitative equivalence between the private PAC model and Littlestones mistakebounded model of online learning, in particular, showing that any concept class of Littlestone dimension d can be privately PAC learned using mathrmpolyd samples. This raises the natural question of whether there might be a generic conversion from online learners to private PAC learners that also preserves computational efficiency. We give a negative answer to this question under reasonable cryptographic assumptions roughly, those from which it is possible to build indistinguishability obfuscation for all circuits. We exhibit a concept class that admits an online learner running in polynomial time with a polynomial mistake bound, but for which there is no computationallyefficient differentially private PAC learner. Our construction and analysis strengthens and generalizes that of Bun and Zhandry TCC 2016A, who established such a separation between private and nonprivate PAC learner.","Fri, 16 Feb 2024 22:44:52 UTC (107 KB)"
"77","Online Flexible Busy Time Scheduling on Heterogeneous Machines","Gruia Calinescu, Sami Davies, Samir Khuller, Shirley Zhang","Data Structures and Algorithms (cs.DS)","We study the online busy time scheduling model on heterogeneous machines. In our setting, unitlength jobs arrive online with a deadline that is known to the algorithm at the jobs arrival time. An algorithm has access to machines, each with different associated capacities and costs. The goal is to schedule jobs on machines before their deadline, so that the total cost incurred by the scheduling algorithm is minimized. Relatively little is known about online busy time scheduling when machines are heterogeneous i.e., have different costs and capacities, despite this being the most practical model for clients using cloud computing services. We make significant progress in understanding this model by designing an 8competitive algorithm for the problem on unitlength jobs, and providing a lower bound on the competitive ratio of 2. We further prove that our lower bound is tight in the natural setting when jobs have agreeable deadlines.","Fri, 16 Feb 2024 22:22:39 UTC (992 KB)"
"78","The Competition Complexity of Prophet Inequalities","Johannes Brustle, José Correa, Paul Dütting, Tomer Ezra, Michal Feldman, Victor Verdugo","Computer Science and Game Theory (cs.GT)","We study the classic singlechoice prophet inequality problem through a resource augmentation lens. Our goal is to bound the 1varepsiloncompetition complexity of different types of online algorithms. This metric asks for the smallest k such that the expected value of the online algorithm on k copies of the original instance, is at least a 1varepsilonapproximation to the expected offline optimum on a single copy. We show that block threshold algorithms, which set one threshold per copy, are optimal and give a tight bound of k  Thetalog log 1varepsilon. This shows that block threshold algorithms approach the offline optimum doublyexponentially fast. For single threshold algorithms, we give a tight bound of k  Thetalog 1varepsilon, establishing an exponential gap between block threshold algorithms and single threshold algorithms. Our model and results pave the way for exploring resourceaugmented prophet inequalities in combinatorial settings. In line with this, we present preliminary findings for bipartite matching with onesided vertex arrivals, as well as in XOS combinatorial auctions. Our results have a natural competition complexity interpretation in mechanism design and pricing applications.","Fri, 16 Feb 2024 21:19:04 UTC (38 KB)[v2] Thu, 22 Feb 2024 09:57:06 UTC (38 KB)"
"79","Incremental Topological Ordering and Cycle Detection with Predictions","Samuel McCauley, Benjamin Moseley, Aidin Niaparast, Shikha Singh","Data Structures and Algorithms (cs.DS)","This paper leverages the framework of algorithmswithpredictions to design data structures for two fundamental dynamic graph problems incremental topological ordering and cycle detection. In these problems, the input is a directed graph on n nodes, and the m edges arrive one by one. The data structure must maintain a topological ordering of the vertices at all times and detect if the newly inserted edge creates a cycle. The theoretically best worstcase algorithms for these problems have high update cost polynomial in n and m. In practice, greedy heuristics that recompute the solution from scratch each time perform well but can have high update cost in the worst case. In this paper, we bridge this gap by leveraging predictions to design a learned new data structure for the problems. Our data structure guarantees consistency, robustness, and smoothness with respect to predictions  that is, it has the best possible running time under perfect predictions, never performs worse than the bestknown worstcase methods, and its running time degrades smoothly with the prediction error. Moreover, we demonstrate empirically that predictions, learned from a very small training dataset, are sufficient to provide significant speedups on real datasets.","Fri, 16 Feb 2024 19:18:51 UTC (2,613 KB)"
"80","Hypergraph Connectivity Augmentation in Strongly Polynomial Time","Kristóf Bérczi, Karthekeyan Chandrasekaran, Tamás Király, Shubhang Kulkarni","Data Structures and Algorithms (cs.DS)","We consider hypergraph network design problems where the goal is to construct a hypergraph that satisfies certain connectivity requirements. For graph network design problems where the goal is to construct a graph that satisfies certain connectivity requirements, the number of edges in every feasible solution is at most quadratic in the number of vertices. In contrast, for hypergraph network design problems, we might have feasible solutions in which the number of hyperedges is exponential in the number of vertices. This presents an additional technical challenge in hypergraph network design problems compared to graph network design problems in order to solve the problem in polynomial time, we first need to show that there exists a feasible solution in which the number of hyperedges is polynomial in the input size. The central theme of this work is to show that certain hypergraph network design problems admit solutions in which the number of hyperedges is polynomial in the number of vertices and moreover, can be solved in strongly polynomial time. Our work improves on the previous fastest pseudopolynomial runtime for these problems. In addition, we develop strongly polynomial time algorithms that return nearuniform hypergraphs as solutions i.e., every pair of hyperedges differ in size by at most one. As applications of our results, we derive the first strongly polynomial time algorithms for i degreespecified hypergraph connectivity augmentation using hyperedges, ii degreespecified hypergraph nodetoarea connectivity augmentation using hyperedges, and iii degreeconstrained mixedhypergraph connectivity augmentation using hyperedges.","Fri, 16 Feb 2024 17:58:58 UTC (219 KB)"
"81","Core Stability in Additively Separable Hedonic Games of Low Treewidth","Tesshu Hanaka, Noleen Köhler, Michael Lampis","Data Structures and Algorithms (cs.DS)","Additively Separable Hedonic Game ASHG are coalitionformation games where we are given a graph whose vertices represent n selfish agents and the weight of each edge uv denotes how much agent u gains or loses when she is placed in the same coalition as agent v. We revisit the computational complexity of the wellknown notion of core stability of ASHGs, where the goal is to construct a partition of the agents into coalitions such that no group of agents would prefer to diverge from the given partition and form a new blocking coalition. Since both finding a core stable partition and verifying that a given partition is core stable are intractable problems Sigma2pcomplete and coNPcomplete respectively we study their complexity from the point of view of structural parameterized complexity, using standard graphtheoretic parameters, such as treewidth.","Fri, 16 Feb 2024 16:39:14 UTC (693 KB)"
"82","Streaming Algorithms for Connectivity Augmentation","Ce Jin, Michael Kapralov, Sepideh Mahabadi, Ali Vakilian","Data Structures and Algorithms (cs.DS)","We study the kconnectivity augmentation problem kCAP in the singlepass streaming model. Given a k1edge connected graph GV,E that is stored in memory, and a stream of weighted edges L with weights in 0,1,dots,W, the goal is to choose a minimum weight subset Lsubseteq L such that GV,Ecup L is kedge connected. We give a 2epsilonapproximation algorithm for this problem which requires to store Oepsilon1 nlog n words. Moreover, we show our result is tight Any algorithm with better than 2approximation for the problem requires Omegan2 bits of space even when k2. This establishes a gap between the optimal approximation factor one can obtain in the streaming vs the offline setting for kCAP. We further consider a natural generalization to the fully streaming model where both E and L arrive in the stream in an arbitrary order. We show that this problem has a space lower bound that matches the best possible size of a spanner of the same approximation ratio. Following this, we give improved results for spanners on weighted graphs We show a streaming algorithm that finds a 2t1epsilonapproximate weighted spanner of size at most Oepsilon1 n11tlog n for integer t, whereas the best prior streaming algorithm for spanner on weighted graphs had size depending on log W. Using our spanner result, we provide an optimal Otapproximation for kCAP in the fully streaming model with Onk  n11t words of space. Finally we apply our results to network design problems such as Steiner tree augmentation problem STAP, kedge connected spanning subgraph kECSS, and the general Survivable Network Design problem SNDP. In particular, we show a singlepass Otlog kapproximation for SNDP using Okn11t words of space, where k is the maximum connectivity requirement.","Fri, 16 Feb 2024 16:34:08 UTC (236 KB)"
"83","On Permutation Selectors and their Applications in Ad-Hoc Radio Networks Protocols","Jordan Kuschner, Yugarshi Shashwat, Sarthak Yadav, Marek Chrobak","Data Structures and Algorithms (cs.DS)","Selective families of sets, or selectors, are combinatorial tools used to isolate individual members of sets from some set family. Given a set X and an element xin X, to isolate x from X, at least one of the sets in the selector must intersect X on exactly x. We study k,Npermutation selectors which have the property that they can isolate each element of each kelement subset of 0,1,...,N1 in each possible order. These selectors can be used in protocols for adhoc radio networks to more efficiently disseminate information along multiple hops. In 2004, Gasieniec, Radzik and Xin gave a construction of a k,Npermutation selector of size Ok2log3 N. This paper improves this by providing a probabilistic construction of a k,Npermutation selector of size Ok2log N. Remarkably, this matches the asymptotic bound for standard strong k,Nselectors, that isolate each element of each set of size k, but with no restriction on the order. We then show that the use of our k,Npermutation selector improves the best running time for gossiping in adhoc radio networks by a polylogarithmic factor.","Fri, 16 Feb 2024 16:05:47 UTC (141 KB)"
"84","Alphabet Reduction for Reconfiguration Problems","Naoto Ohsaka","Computational Complexity (cs.CC)","We present a reconfiguration analogue of alphabet reduction  la Dinur J. ACM, 2007 and its applications. Given a binary constraint graph G and its two satisfying assignments psimathsfini and psimathsftar, the Maxmin Binary CSP Reconfiguration problem requests to transform psimathsfini into psimathsftar by repeatedly changing the value of a single vertex so that the minimum fraction of satisfied edges is maximized. We demonstrate a polynomialtime reduction from Maxmin Binary CSP Reconfiguration with arbitrarily large alphabet size W in mathbbN to itself with universal alphabet size W0 in mathbbN such that 1. the perfect completeness is preserved, and 2. if any reconfiguration for the former violates varepsilonfraction of edges, then Omegavarepsilonfraction of edges must be unsatisfied during any reconfiguration for the latter. The crux of its construction is the reconfigurability of Hadamard codes, which enables to reconfigure between a pair of codewords, while avoiding getting too close to the other codewords. Combining this alphabet reduction with gap amplification due to Ohsaka SODA 2024, we are able to amplify the 1 vs. 1varepsilon gap for arbitrarily small varepsilon in 0,1 up to the 1 vs. 1varepsilon0 for some universal varepsilon0 in 0,1 without blowing up the alphabet size. In particular, a 1 vs. 1varepsilon0 gap version of Maxmin Binary CSP Reconfiguration with alphabet size W0 is PSPACEhard only assuming the Reconfiguration Inapproximability Hypothesis posed by Ohsaka STACS 2023, whose gap parameter can be arbitrarily small. This may not be achieved only by gap amplification of Ohsaka, which makes the alphabet size gigantic depending on the gap value of the hypothesis.","Fri, 16 Feb 2024 12:26:57 UTC (156 KB)"
"85","Learning-Augmented Skip Lists","Chunkai Fu, Jung Hoon Seo, Samson Zhou","Data Structures and Algorithms (cs.DS)","We study the integration of machine learning advice into the design of skip lists to improve upon traditional data structure design. Given access to a possibly erroneous oracle that outputs estimated fractional frequencies for search queries on a set of items, we construct a skip list that provably provides the optimal expected search time, within nearly a factor of two. In fact, our learningaugmented skip list is still optimal up to a constant factor, even if the oracle is only accurate within a constant factor. We show that if the search queries follow the ubiquitous Zipfian distribution, then the expected search time for an item by our skip list is only a constant, independent of the total number n of items, i.e., mathcalO1, whereas a traditional skip list will have an expected search time of mathcalOlog n. We also demonstrate robustness by showing that our data structure achieves an expected search time that is within a constant factor of an oblivious skip list construction even when the predictions are arbitrarily incorrect. Finally, we empirically show that our learningaugmented skip list outperforms traditional skip lists on both synthetic and realworld datasets.","Fri, 16 Feb 2024 05:27:13 UTC (3,927 KB)"
"86","Composition Orderings for Linear Functions and Matrix Multiplication Orderings","Susumu Kubo, Kazuhisa Makino, Souta Sakamoto","Data Structures and Algorithms (cs.DS)","We consider composition orderings for linear functions of one variable. Given n linear functions f1,dots,fn and a constant c, the objective is to find a permutation sigma that minimizesmaximizes fsigmancircdotscirc fsigma1c. It was first studied in the area of timedependent scheduling, and known to be solvable in Onlog n time if all functions are nondecreasing. In this paper, we present a complete characterization of optimal composition orderings for this case, by regarding linear functions as twodimensional vectors. We also show several interesting properties on optimal composition orderings such as the equivalence between local and global optimality. Furthermore, by using the characterization above, we provide a fixedparameter tractable FPT algorithm for the composition ordering problem for general linear functions, with respect to the number of decreasing linear functions. We next deal with matrix multiplication orderings as a generalization of composition of linear functions. Given n matrices M1,dots,MninmathbbRmtimes m and two vectors w,yinmathbbRm, where m denotes a positive integer, the objective is to find a permutation sigma that minimizesmaximizes wtop Msigmandots Msigma1 y. The problem is also viewed as a generalization of flow shop scheduling through a limit. By this extension, we show that the multiplication ordering problem for 2times 2 matrices is solvable in Onlog n time if all the matrices are simultaneously triangularizable and have nonnegative determinants, and FPT with respect to the number of matrices with negative determinants, if all the matrices are simultaneously triangularizable. As the negative side, we finally prove that three possible natural generalizations are NPhard 1 when m2, 2 when mgeq 3, and 3 the target version of the problem.","Fri, 16 Feb 2024 04:55:49 UTC (143 KB)"
"87","Collaborative Learning with Different Labeling Functions","Yuyang Deng, Mingda Qiao","Machine Learning (cs.LG)","We study a variant of Collaborative PAC Learning, in which we aim to learn an accurate classifier for each of the n data distributions, while minimizing the number of samples drawn from them in total. Unlike in the usual collaborative learning setup, it is not assumed that there exists a single classifier that is simultaneously accurate for all distributions. We show that, when the data distributions satisfy a weaker realizability assumption, sampleefficient learning is still feasible. We give a learning algorithm based on Empirical Risk Minimization ERM on a natural augmentation of the hypothesis class, and the analysis relies on an upper bound on the VC dimension of this augmented class. In terms of the computational efficiency, we show that ERM on the augmented hypothesis class is NPhard, which gives evidence against the existence of computationally efficient learners in general. On the positive side, for two special cases, we give learners that are both sample and computationallyefficient.","Fri, 16 Feb 2024 04:32:22 UTC (38 KB)[v2] Tue, 20 Feb 2024 05:14:09 UTC (34 KB)"
"88","Learnability is a Compact Property","Julian Asilis, Siddartha Devic, Shaddin Dughmi, Vatsal Sharan, Shang-Hua Teng","Machine Learning (cs.LG)","Recent work on learning has yielded a striking result the learnability of various problems can be undecidable, or independent of the standard ZFC axioms of set theory. Furthermore, the learnability of such problems can fail to be a property of finite character informally, it cannot be detected by examining finite projections of the problem. On the other hand, learning theory abounds with notions of dimension that characterize learning and consider only finite restrictions of the problem, i.e., are properties of finite character. How can these results be reconciled? More precisely, which classes of learning problems are vulnerable to logical undecidability, and which are within the grasp of finite characterizations? We demonstrate that the difficulty of supervised learning with metric losses admits a tight finite characterization. In particular, we prove that the sample complexity of learning a hypothesis class can be detected by examining its finite projections. For realizable and agnostic learning with respect to a wide class of proper loss functions, we demonstrate an exact compactness result a class is learnable with a given sample complexity precisely when the same is true of all its finite projections. For realizable learning with improper loss functions, we show that exact compactness of sample complexity can fail, and provide matching upper and lower bounds of a factor of 2 on the extent to which such sample complexities can differ. We conjecture that larger gaps are possible for the agnostic case. At the heart of our technical work is a compactness result concerning assignments of variables that maintain a class of functions below a target value, which generalizes Halls classic matching theorem and may be of independent interest.","Thu, 15 Feb 2024 23:10:45 UTC (53 KB)"
"89","Non-adaptive Bellman-Ford: Yen's improvement is optimal","Jialu Hu, László Kozma","Data Structures and Algorithms (cs.DS)","The BellmanFord algorithm for singlesource shortest paths repeatedly updates tentative distances in an operation called relaxing an edge. In several important applications a nonadaptive oblivious implementation is preferred, which means fixing the entire sequence of relaxations upfront, independent of the edgeweights. In a dense graph on n vertices, the algorithm in its standard form performs 1  o1n3 relaxations. An improvement by Yen from 1970 reduces the number of relaxations by a factor of two. We show that no further constantfactor improvements are possible, and every nonadaptive deterministic algorithm based on relaxations must perform frac12  o1n3 steps. This improves an earlier lower bound of Eppstein of frac16  o1n3. Given that a nonadaptive randomized variant of BellmanFord with at most frac13  o1n3 relaxations with high probability is known, our result implies a strict separation between deterministic and randomized strategies, answering an open question of Eppstein.","Thu, 15 Feb 2024 22:13:47 UTC (7 KB)"
"90","Correlation Clustering with Vertex Splitting","Matthias Bentert, Alex Crane, Pål Grønås Drange, Felix Reidl, Blair D. Sullivan","Data Structures and Algorithms (cs.DS)","We explore Cluster Editing and its generalization Correlation Clustering with a new operation called permissive vertex splitting which addresses finding overlapping clusters in the face of uncertain information. We determine that both problems are NPhard, yet they exhibit significant differences in parameterized complexity and approximability. For Cluster Editing with Permissive Vertex Splitting, we show a polynomial kernel when parameterized by the solution size and develop a polynomialtime algorithm with approximation factor 7. In the case of Correlation Clustering, we establish paraNPhardness when parameterized by solution size and demonstrate that computing an n1epsilonapproximation is NPhard for any constant epsilon  0. Additionally, we extend the established link between Correlation Clustering and Multicut to the setting with permissive vertex splitting.","Thu, 15 Feb 2024 21:45:10 UTC (24 KB)"
"91","Streaming algorithm for balance gain and cost with cardinality constraint on the integer lattice","Jingjing Tan","Data Structures and Algorithms (cs.DS)","Team formation problem is a very important problem in the labor market, and it is proved to be NPhard. In this paper, we design an efficient bicriteria streaming algorithms to construct a balance between gain and cost in a team formation problem with cardinality constraint on the integer lattice. To solve this problem, we establish a model for maximizing the difference between a nonnegative normalized monotone submodule function and a nonnegative linear function. Further, we discuss the case where the first function of the object function is alphaweakly submodular. Combining the lattice binary search with the threshold method, we present an online algorithm called bicriteria streaming algorithms. Meanwhile, we give detailed analysis for both of these models.","Thu, 15 Feb 2024 19:57:32 UTC (15 KB)"
"92","Simple, unified analysis of Johnson-Lindenstrauss with applications","Yingru Li","Machine Learning (stat.ML)","In this work, we present a simple and unified analysis of the JohnsonLindenstrauss JL lemma, a cornerstone in the field of dimensionality reduction critical for managing highdimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, binarycoin, sparse JL, Gaussian and subGaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical constructions effectiveness and provide a general class of subGaussian constructions within this simplified framework. At the heart of our contribution is an innovative extension of the HansonWright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and analytical techniques, such as an enhanced diagonalization process, our analysis not only solidifies the JL lemmas theoretical foundation but also extends its practical reach, showcasing its adaptability and importance in contemporary computational algorithms.","Sat, 10 Feb 2024 15:37:46 UTC (30 KB)[v2] Wed, 21 Feb 2024 15:30:52 UTC (37 KB)"
"93","Trainability Barriers in Low-Depth QAOA Landscapes","Joel Rajakumar, John Golden, Andreas Bärtschi, Stephan Eidenbenz","Quantum Physics (quant-ph)","The Quantum Alternating Operator Ansatz QAOA is a prominent variational quantum algorithm for solving combinatorial optimization problems. Its effectiveness depends on identifying input parameters that yield highquality solutions. However, understanding the complexity of training QAOA remains an underexplored area. Previous results have given analytical performance guarantees for a small, fixed number of parameters. At the opposite end of the spectrum, barren plateaus are likely to emerge at Omegan parameters for n qubits. In this work, we study the difficulty of training in the intermediate regime, which is the focus of most current numerical studies and nearterm hardware implementations. Through extensive numerical analysis of the quality and quantity of local minima, we argue that QAOA landscapes can exhibit a superpolynomial growth in the number of lowquality local minima even when the number of parameters scales logarithmically with n. This means that the common technique of gradient descent from randomly initialized parameters is doomed to fail beyond small n, and emphasizes the need for good initial guesses of the optimal parameters.","Thu, 15 Feb 2024 18:45:30 UTC (977 KB)"
"94","Quantum Backtracking in Qrisp Applied to Sudoku Problems","Raphael Seidel, René Zander, Matic Petrič, Niklas Steinmann, David Q. Liu, Nikolay Tcholtchev, Manfred Hauswirth","Quantum Physics (quant-ph)","The quantum backtracking algorithm proposed by Ashley Montanaro raised considerable interest, as it provides a quantum speedup for a large class of classical optimization algorithms. It does not suffer from BarrenPlateaus and transfers well into the faulttolerant era, as it requires only a limited number of arbitrary angle gates. Despite its potential, the algorithm has seen limited implementation efforts, presumably due to its abstract formulation. In this work, we provide a detailed instruction on implementing the quantum step operator for arbitrary backtracking instances. For a single controlled diffuser of a binary backtracking tree with depth n, our implementation requires only 6n14 CX gates. We detail the process of constructing accept and reject oracles for Sudoku problems using our interface to quantum backtracking. The presented code is written using Qrisp, a highlevel quantum programming language, making it executable on most current physical backends and simulators. Subsequently, we perform several simulator based experiments and demonstrate solving 4x4 Sudoku instances with up to 9 empty fields. This is, to the best of our knowledge, the first instance of a compilable implementation of this generality, marking a significant and exciting step forward in quantum software engineering.","Thu, 15 Feb 2024 16:29:44 UTC (343 KB)"
"95","A Piecewise Approach for the Analysis of Exact Algorithms","Katie Clinch, Serge Gaspers, Abdallah Saffidine, Tiankuang Zhang","Data Structures and Algorithms (cs.DS)","To analyze the worstcase running time of branching algorithms, the majority of work in exponential time algorithms focuses on designing complicated branching rules over developing better analysis methods for simple algorithms. In the mid2000s, Fomin et al. 2005 introduced measure  conquer, an advanced general analysis method, sparking widespread adoption for obtaining tighter worstcase running time upper bounds for many fundamental NPcomplete problems. Yet, much potential in this direction remains untapped, as most subsequent work applied it without further advancement. Motivated by this, we present piecewise analysis, a new general method that analyzes the running time of branching algorithms. Our approach is to define a similarity ratio that divides instances into groups and then analyze the running time within each group separately. The similarity ratio is a scale between two parameters of an instance I. Instead of relying on a single measure and a single analysis for the whole instance space, our method allows to take advantage of different intrinsic properties of instances with different similarity ratios. To showcase its potential, we reanalyze two 17yearold algorithms from Fomin et al. 2007 that solve 4Coloring and 3Coloring respectively. The original analysis in their paper gave running times of O1.7272n and O1.6262n respectively for these algorithms, our analysis improves these running times to O1.7215n and O1.6232n. Among the two improvements, our new running time O1.7215n is the first improvement in the best known running time for the 4Coloring problem since 2007.","Thu, 15 Feb 2024 15:28:10 UTC (1,288 KB)"
"96","Parameterized Vertex Integrity Revisited","Tesshu Hanaka, Michael Lampis, Manolis Vasilakis, Kanae Yoshiwatari","Data Structures and Algorithms (cs.DS)","Vertex integrity is a graph parameter that measures the connectivity of a graph. Informally, its meaning is that a graph has small vertex integrity if it has a small separator whose removal disconnects the graph into connected components which are themselves also small. Graphs with low vertex integrity are extremely structured this renders many hard problems tractable and has recently attracted interest in this notion from the parameterized complexity community. In this paper we revisit the NPcomplete problem of computing the vertex integrity of a given graph from the point of view of structural parameterizations. We present a number of new results, which also answer some recently posed open questions from the literature. Specifically We show that unweighted vertex integrity is W1hard parameterized by treedepth we show that the problem remains W1hard if we parameterize by feedback edge set size via a reduction from a Bin Packing variant which may be of independent interest and complementing this we show that the problem is FPT by maxleaf number. Furthermore, for weighted vertex integrity, we show that the problem admits a singleexponential FPT algorithm parameterized by vertex cover or by modular width, the latter result improving upon a previous algorithm which required weights to be polynomially bounded.","Thu, 15 Feb 2024 14:28:01 UTC (204 KB)"
"97","Parameterized Algorithms for Steiner Forest in Bounded Width Graphs","Andreas Emil Feldmann, Michael Lampis","Data Structures and Algorithms (cs.DS)","In this paper we reassess the parameterized complexity and approximability of the wellstudied Steiner Forest problem in several graph classes of bounded width. The problem takes an edgeweighted graph and pairs of vertices as input, and the aim is to find a minimum cost subgraph in which each given vertex pair lies in the same connected component. It is known that this problem is APXhard in general, and NPhard on graphs of treewidth 3, treedepth 4, and feedback vertex set size 2. However, Bateni, Hajiaghayi and Marx JACM, 2011 gave an approximation scheme with a runtime of nOfrack2varepsilon on graphs of treewidth k. Our main result is a much faster efficient parameterized approximation scheme EPAS with a runtime of 2Ofrack2varepsilon log frack2varepsilon cdot nO1. If k instead is the vertex cover number of the input graph, we show how to compute the optimum solution in 2Ok log k cdot nO1 time, and we also prove that this runtime dependence on k is asymptotically best possible, under ETH. Furthermore, if k is the size of a feedback edge set, then we obtain a faster 2Ok cdot nO1 time algorithm, which again cannot be improved under ETH.","Thu, 15 Feb 2024 09:55:51 UTC (67 KB)"
"98","On the adversarial robustness of Locality-Sensitive Hashing in Hamming space","Michael Kapralov, Mikhail Makarov, Christian Sohler","Data Structures and Algorithms (cs.DS)","Localitysensitive hashingIndyk,Motwani98 is a classical data structure for approximate nearest neighbor search. It allows, after a close to linear time preprocessing of the input dataset, to find an approximately nearest neighbor of any fixed query in sublinear time in the dataset size. The resulting data structure is randomized and succeeds with high probability for every fixed query. In many modern applications of nearest neighbor search the queries are chosen adaptively. In this paper, we study the robustness of the localitysensitive hashing to adaptive queries in Hamming space. We present a simple adversary that can, under mild assumptions on the initial point set, provably find a query to the approximate near neighbor search data structure that the data structure fails on. Crucially, our adaptive algorithm finds the hard query exponentially faster than random sampling.","Thu, 15 Feb 2024 04:58:35 UTC (3,735 KB)"
"99","Robust Learning-Augmented Dictionaries","Ali Zeynali, Shahin Kamali, Mohammad Hajiesmaili","Data Structures and Algorithms (cs.DS)","We present the first learningaugmented data structure for implementing dictionaries with optimal consistency and robustness. Our data structure, named RobustSL, is a skip list augmented by predictions of access frequencies of elements in a data sequence. With proper predictions, RobustSL has optimal consistency achieves static optimality. At the same time, it maintains a logarithmic running time for each operation, ensuring optimal robustness, even if predictions are generated adversarially. Therefore, RobustSL has all the advantages of the recent learningaugmented data structures of Lin, Luo, and Woodruff ICML 2022 and Cao et al. arXiv 2023, while providing robustness guarantees that are absent in the previous work. Numerical experiments show that RobustSL outperforms alternative data structures using both synthetic and real datasets.","Thu, 15 Feb 2024 03:45:44 UTC (13,166 KB)"
"100","HyperMagNet: A Magnetic Laplacian based Hypergraph Neural Network","Tatyana Benko, Martin Buck, Ilya Amburg, Stephen J. Young, Sinan G. Aksoy","Machine Learning (cs.LG)","In data science, hypergraphs are natural models for data exhibiting multiway relations, whereas graphs only capture pairwise. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a nonreversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix  the magnetic Laplacian  which serves as the input to our proposed hypergraph neural network. We study HyperMagNet for the task of node classification, and demonstrate its effectiveness over graphreduction based hypergraph neural networks.","Thu, 15 Feb 2024 03:05:45 UTC (300 KB)"
"101","Unbalanced Random Matching Markets with Partial Preferences","Aditya Potukuchi, Shikha Singh","Computer Science and Game Theory (cs.GT)","Properties of stable matchings in the popular randommatchingmarket model have been studied for over 50 years. In a random matching market, each agent has complete preferences drawn uniformly and independently at random. Wilson 1972, Knuth 1976 and Pittel 1989 proved that in balanced random matching markets, the proposers are matched to their ln nth choice on average. In this paper, we consider markets where agents have partial truncated preferences, that is, the proposers only rank their top d partners. Despite the long history of the problem, the following fundamental question remained unanswered emphwhat is the smallest value of d that results in a perfect stable matching with high probability? In this paper, we answer this question exactly  we prove that a degree of ln2 n is necessary and sufficient. That is, we show that if d  1epsilon ln2 n then no stable matching is perfect and if d  1 epsilon ln2 n, then every stable matching is perfect with high probability. This settles a recent conjecture by Kanoria, Min and Qian 2021. We generalize this threshold for unbalanced markets we consider a matching market with n agents on the shorter side and nalpha1 agents on the longer side. We show that for markets with alpha o1, the sharp threshold characterizing the existence of perfect stable matching occurs when d is ln n cdot ln leftfrac1  alphaalpha  1nalpha1 right. Finally, we extend the line of work studying the effect of imbalance on the expected rank of the proposers termed the stark effect of competition. We establish the regime in unbalanced markets that forces this stark effect to take shape in markets with partial preferences.","Thu, 15 Feb 2024 02:27:51 UTC (47 KB)"
"102","Fixed-sparsity matrix approximation from matrix-vector products","Noah Amsel, Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco","Data Structures and Algorithms (cs.DS)","We study the problem of approximating a matrix mathbfA with a matrix that has a fixed sparsity pattern e.g., diagonal, banded, etc., when mathbfA is accessed only by matrixvector products. We describe a simple randomized algorithm that returns an approximation with the given sparsity pattern with Frobeniusnorm error at most 1varepsilon times the best possible error. When each row of the desired sparsity pattern has at most s nonzero entries, this algorithm requires Osvarepsilon nonadaptive matrixvector products with mathbfA. We also prove a matching lowerbound, showing that, for any sparsity pattern with Thetas nonzeros per row and column, any algorithm achieving 1epsilon approximation requires Omegasvarepsilon matrixvector products in the worst case. We thus resolve the matrixvector product query complexity of the problem up to constant factors, even for the wellstudied case of diagonal approximation, for which no previous lower bounds were known.","Wed, 14 Feb 2024 18:25:13 UTC (605 KB)[v2] Thu, 15 Feb 2024 17:18:05 UTC (605 KB)"
"103","A Modern Approach to Electoral Delimitation using the Quadtree Data Structure","Sahil Kale, Gautam Khaire, Jay Patankar, Pujashree Vidap","Data Structures and Algorithms (cs.DS)","The boundaries of electoral constituencies for assembly and parliamentary seats are drafted using a process referred to as delimitation, which ensures fair and equal representation of all citizens. The current delimitation exercise suffers from a number of drawbacks viz. inefficiency, gerrymandering and an uneven seattopopulation ratio, owing to existing legal and constitutional dictates. The existing methods allocate seats to every state but remain silent about their actual shape and location within the state. The main purpose of this research is to study and analyse the performance of existing delimitation algorithms and further propose a potential solution, along with its merits, that involves using a computational model based on the quadtree data structure to automate the districting process by optimizing objective population criteria. The paper presents an approach to electoral delimitation using the quadtree data structure, which is used to partition a twodimensional geographical space by recursively subdividing it into four quadrants or regions on the basis of population as a parameter value associated with the node. The quadtree makes use of a quadrant schema of the geographical space for representing constituencies, which not only keeps count of the allocated constituencies but also holds their locationspecific information. The performance of the proposed algorithm is analysed and evaluated against existing techniques and proves to be an efficient solution in terms of algorithmic complexity and boundary visualisation to the process of political districting.","Wed, 14 Feb 2024 17:32:57 UTC (484 KB)[v2] Fri, 16 Feb 2024 14:24:53 UTC (484 KB)"
"104","Efficient Unitary T-designs from Random Sums","Chi-Fang Chen, Jordan Docter, Michelle Xu, Adam Bouland, Patrick Hayden","Quantum Physics (quant-ph)","Unitary Tdesigns play an important role in quantum information, with diverse applications in quantum algorithms, benchmarking, tomography, and communication. Until now, the most efficient construction of unitary Tdesigns for nqudit systems has been via random local quantum circuits, which have been shown to converge to approximate Tdesigns in the diamond norm using OT5o1 n2 quantum gates. In this work, we provide a new construction of Tdesigns via random matrix theory using tildeOT2 n2 quantum gates. Our construction leverages two key ideas. First, in the spirit of central limit theorems, we approximate the Gaussian Unitary Ensemble GUE by an i.i.d. sum of random Hermitian matrices. Second, we show that the product of just two exponentiated GUE matrices is already approximately Haar random. Thus, multiplying two exponentiated sums over rather simple random matrices yields a unitary Tdesign, via Hamiltonian simulation. A central feature of our proof is a new connection between the polynomial method in quantum query complexity and the largedimension N expansion in random matrix theory. In particular, we show that the polynomial method provides exponentially improved bounds on the high moments of certain random matrix ensembles, without requiring intricate Weingarten calculations. In doing so, we define and solve a new type of moment problem on the unit circle, asking whether a finite number of equally weighted points, corresponding to eigenvalues of unitary matrices, can reproduce a given set of moments.","Wed, 14 Feb 2024 17:32:30 UTC (232 KB)"
"105","Iterated Straight-Line Programs","Gonzalo Navarro, Cristian Urbina","Data Structures and Algorithms (cs.DS)","We explore an extension to straightline programs SLPs that outperforms, for some text families, the measure delta based on substring complexity, a lower bound for most measures and compressors exploiting repetitiveness which are crucial in areas like Bioinformatics. The extension, called iterated SLPs ISLPs, allows rules of the form A rightarrow Piik1k2 B1ic1cdots Btict, for which we show how to extract any substring of length lambda, from the represented text T1.. n, in time Olambda  log2 nloglog n. This is the first compressed representation for repetitive texts breaking delta while, at the same time, supporting direct access to arbitrary text symbols in polylogarithmic time. As a byproduct, we extend Ganardi et al.s technique to balance any SLP so it has a derivation tree of logarithmic height to a wide generalization of SLPs, including ISLPs.","Wed, 14 Feb 2024 15:21:37 UTC (43 KB)[v2] Thu, 15 Feb 2024 09:21:39 UTC (39 KB)"
"106","Better Decremental and Fully Dynamic Sensitivity Oracles for Subgraph Connectivity","Yaowei Long, Yunfan Wang","Data Structures and Algorithms (cs.DS)","We study the emphsensitivity oracles problem for subgraph connectivity in the emphdecremental and emphfully dynamic settings. In the fully dynamic setting, we preprocess an nvertices medges undirected graph G with nrm off deactivated vertices initially and the others are activated. Then we receive a single update Dsubseteq VG of size D  d leq dstar, representing vertices whose states will be switched. Finally, we get a sequence of queries, each of which asks the connectivity of two given vertices u and v in the activated subgraph. The decremental setting is a special case when there is no deactivated vertex initially, and it is also known as the emphvertexfailure connectivity oracles problem. We present a better deterministic vertexfailure connectivity oracle with widehatOdstarm preprocessing time, widetildeOm space, widetildeOd2 update time and Od query time, which improves the update time of the previous almostoptimal oracle LongSaranurak, FOCS 2022 from widehatOd2 to widetildeOd2. We also present a better deterministic fully dynamic sensitivity oracle for subgraph connectivity with widehatOminmnrm off  dstar,nomega preprocessing time, widetildeOminmnrm off  dstar,n2 space, widetildeOd2 update time and Od query time, which significantly improves the update time of the state of the art HuKosinasPolak, 2023 from widetildeOd4 to widetildeOd2. Furthermore, our solution is even almostoptimal assuming popular finegrained complexity conjectures.","Wed, 14 Feb 2024 12:59:43 UTC (32 KB)"
"107","Improved Deterministic Distributed Maximum Weight Independent Set Approximation in Sparse Graphs","Yuval Gil","Data Structures and Algorithms (cs.DS)","We design new deterministic CONGEST approximation algorithms for emphmaximum weight independent set MWIS in emphsparse graphs. As our main results, we obtain new Delta1epsilonapproximation algorithms as well as algorithms whose approximation ratio depend strictly on alpha, in graphs with maximum degree Delta and arboricity alpha. For deterministic Delta1epsilonapproximation, the current stateoftheart is due to a recent breakthrough by Faour et al. SODA 2023 that showed an Olog2 Delta Wcdot log 1epsilonlog nround algorithm, where W is the largest nodeweight this bound translates to Olog2 ncdotlog 1epsilon under the common assumption that Wtextpolyn. As for alphadependent approximations, a deterministic CONGEST 81epsiloncdotalphaapproximation algorithm with runtime Olog3 ncdotlog 1epsilon can be derived by combining the aforementioned algorithm of Faour et al. with a method presented by Kawarabayashi et al. DISC 2020.","Wed, 14 Feb 2024 08:36:52 UTC (22 KB)"
"108","Sequence graphs realizations and ambiguity in language models","Sammy Khalife, Yann Ponty, Laurent Bulteau","Data Structures and Algorithms (cs.DS)","Several popular language models represent local contexts in an input text as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the ordered cooccurrence of two words within a sliding window of size w. However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity. Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings window size w, presenceabsence of graph orientation, and presenceabsence of weights multiplicities. When w  2, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirectedweighted setting, where we show the Phardness of enumeration. For a window of size at least 3, we prove hardness of all variants, even when w is considered as a constant, with the notable exception of the undirectedunweighted case for which we propose an XP algorithms for both realizability and enumeration problems, tight due to a corresponding W1hardness result. We conclude with an integer program formulation to solve the realizability problem, and with dynamic programming to solve the enumeration problem. This work leaves open the membership to NP for both problems, a nontrivial question due to the existence of minimum realizations having exponential size on the instance encoding.","Tue, 13 Feb 2024 22:22:51 UTC (71 KB)"
"109","Parameterized dynamic data structure for Split Completion","Konrad Majewski, Michał Pilipczuk, Anna Zych-Pawlewicz","Data Structures and Algorithms (cs.DS)","We design a randomized data structure that, for a fully dynamic graph G updated by edge insertions and deletions and integers k, d fixed upon initialization, maintains the answer to the Split Completion problem whether one can add k edges to G to obtain a split graph. The data structure can be initialized on an edgeless nvertex graph in time n cdot k d cdot log nmathcalO1, and the amortized time complexity of an update is 5k cdot k d cdot log nmathcalO1. The answer provided by the data structure is correct with probability 1mathcalOnd.","Tue, 13 Feb 2024 21:46:53 UTC (987 KB)"
"110","Deep and shallow data science for multi-scale optical neuroscience","Gal Mishne, Adam Charles","Image and Video Processing (eess.IV)","Optical imaging of the brain has expanded dramatically in the past two decades. New optics, indicators, and experimental paradigms are now enabling invivo imaging from the synaptic to the cortexwide scales. To match the resulting flood of data across scales, computational methods are continuously being developed to meet the need of extracting biologically relevant information. In this pursuit, challenges arise in some domains e.g., SNR and resolution limits in micronscale data that require specialized algorithms. These algorithms can, for example, make use of stateoftheart machine learning to maximally learn the details of a given scale to optimize the processing pipeline. In contrast, other methods, however, such as graph signal processing, seek to abstract away from some of the details that are scalespecific to provide solutions to specific subproblems common across scales of neuroimaging. Here we discuss limitations and tradeoffs in algorithmic design with the goal of identifying how data quality and variability can hamper algorithm use and dissemination.","Tue, 13 Feb 2024 21:30:44 UTC (21 KB)"
"111","Almost Tight Bounds for Online Hypergraph Matching","Thorben Tröbst, Rajan Udwani","Data Structures and Algorithms (cs.DS)","In the online hypergraph matching problem, hyperedges of size k over a common ground set arrive online in adversarial order. The goal is to obtain a maximum matching disjoint set of hyperedges. A nave greedy algorithm for this problem achieves a competitive ratio of frac1k. We show that no randomized online algorithm has competitive ratio better than frac2o1k. If edges are allowed to be assigned fractionally, we give a deterministic online algorithm with competitive ratio frac1o1lnk and show that no online algorithm can have competitive ratio strictly better than frac1o1lnk. Lastly, we give a frac1o1lnk competitive algorithm for the fractional edgeweighted version of the problem under a free disposal assumption.","Tue, 13 Feb 2024 20:17:24 UTC (34 KB)"
"112","Data Analytics for Intermodal Freight Transportation Applications","Nathan Huynh, Majbah Uddin, Chu Cong Minh","Methodology (stat.ME)","With the growth of intermodal freight transportation, it is important that transportation planners and decision makers are knowledgeable about freight flow data to make informed decisions. This is particularly true with Intelligent Transportation Systems ITS offering new capabilities to intermodal freight transportation. Specifically, ITS enables access to multiple different data sources, but they have different formats, resolution, and time scales. Thus, knowledge of data science is essential to be successful in future ITSenabled intermodal freight transportation system. This chapter discusses the commonly used descriptive and predictive data analytic techniques in intermodal freight transportation applications. These techniques cover the entire spectrum of univariate, bivariate, and multivariate analyses. In addition to illustrating how to apply these techniques through relatively simple examples, this chapter will also show how to apply them using the statistical software R. Additional exercises are provided for those who wish to apply the described techniques to more complex problems.","Tue, 13 Feb 2024 17:41:43 UTC (555 KB)"
"113","Primal-Dual Algorithms with Predictions for Online Bounded Allocation and Ad-Auctions Problems","Eniko Kevi, Nguyen Kim Thang","Data Structures and Algorithms (cs.DS)","Matching problems have been widely studied in the research community, especially AdAuctions with many applications ranging from network design to advertising. Following the various advancements in machine learning, one natural question is whether classical algorithms can benefit from machine learning and obtain betterquality solutions. Even a small percentage of performance improvement in matching problems could result in significant gains for the studied use cases. For example, the network throughput or the revenue of AdAuctions can increase remarkably. This paper presents algorithms with machine learning predictions for the Online Bounded Allocation and the Online AdAuctions problems. We constructed primaldual algorithms that achieve competitive performance depending on the quality of the predictions. When the predictions are accurate, the algorithms performance surpasses previous performance bounds, while when the predictions are misleading, the algorithms maintain standard worstcase performance guarantees. We provide supporting experiments on generated data for our theoretical findings.","Tue, 13 Feb 2024 13:02:11 UTC (79 KB)"
"114","Strategizing against No-Regret Learners in First-Price Auctions","Aviad Rubinstein, Junyao Zhao","Computer Science and Game Theory (cs.GT)","We study repeated firstprice auctions and general repeated Bayesian games between two players, where one player, the learner, employs a noregret learning algorithm, and the other player, the optimizer, knowing the learners algorithm, strategizes to maximize its own utility. For a commonly used class of noregret learning algorithms called meanbased algorithms, we show that i in standard i.e., fullinformation firstprice auctions, the optimizer cannot get more than the Stackelberg utility  a standard benchmark in the literature, but ii in Bayesian firstprice auctions, there are instances where the optimizer can achieve much higher than the Stackelberg utility. On the other hand, Mansour et al. 2022 showed that a more sophisticated class of algorithms called nopolytopeswapregret algorithms are sufficient to cap the optimizers utility at the Stackelberg utility in any repeated Bayesian game including Bayesian firstprice auctions, and they pose the open question whether nopolytopeswapregret algorithms are necessary to cap the optimizers utility. For general Bayesian games, under a reasonable and necessary condition, we prove that nopolytopeswapregret algorithms are indeed necessary to cap the optimizers utility and thus answer their open question. For Bayesian firstprice auctions, we give a simple improvement of the standard algorithm for minimizing the polytope swap regret by exploiting the structure of Bayesian firstprice auctions.","Tue, 13 Feb 2024 18:03:56 UTC (37 KB)"
"115","Sampling Space-Saving Set Sketches","Homin K. Lee, Charles Masson","Data Structures and Algorithms (cs.DS)","Large, distributed data streams are now ubiquitous. Highaccuracy sketches with low memory overhead have become the de facto method for analyzing this data. For instance, if we wish to group data by some label and report the largest counts using fixed memory, we need to turn to mergeable heavy hitter sketches that can provide highly accurate approximate counts. Similarly, if we wish to keep track of the number of distinct items in a single set spread across several streams using fixed memory, we can turn to mergeable count distinct sketches that can provide highly accurate set cardinalities. If we were to try to keep track of the cardinality of multiple sets and report only on the largest ones, maintaining individual count distinct sketches for each set can grow unwieldy, especially if the number of sets is not known in advance. We consider the natural combination of the heavy hitters problem with the count distinct problem, the heavy distinct hitters problem given a stream of ell, x pairs, find all the labels ell that are paired with a large number of distinct items x using only constant memory. No previous work on heavy distinct hitters has managed to be of practical use in the large, distributed data stream setting. We propose a new algorithm, the Sampling SpaceSaving Set Sketch, which combines sketching and sampling techniques and has all the desired properties for size, speed, accuracy, mergeability, and invertibility. We compare our algorithm to several existing solutions to the heavy distinct hitters problem, and provide experimental results across several data sets showing the superiority of the new sketch.","Tue, 13 Feb 2024 17:10:58 UTC (86 KB)"
"116","Polynomial-Time Algorithms for Weaver's Discrepancy Problem in a Dense Regime","Ben Jourdan, Peter Macgregor, He Sun","Data Structures and Algorithms (cs.DS)","Given v1,ldots, vminmathbbCd with vi2 alpha for all iinm as input and suppose sumi1m  langle u, vi rangle 2  1 for every unit vector uinmathbbCd, Weavers discrepancy problem asks for a partition S1, S2 of m, such that sumiin Sj langle u, vi rangle2 leq 1 theta for some universal constant theta, every unit vector uinmathbbCd and every jin1,2. We prove that this problem can be solved deterministically in polynomial time when mgeq 49 d2.","Tue, 13 Feb 2024 15:50:34 UTC (22 KB)"
"117","Tight (Double) Exponential Bounds for Identification Problems: Locating-Dominating Set and Test Cover","Dipayan Chakraborty, Florent Foucaud, Diptapriyo Majumdar, Prafullkumar Tale","Data Structures and Algorithms (cs.DS)","We investigate finegrained algorithmic aspects of identification problems in graphs and set systems, with a focus on LocatingDominating Set and Test Cover. We prove, among other things, the following three tight conditional lower bounds. beginenumerate item textscLocatingDominating Set does not admit an algorithm running in time 2ok2 cdot polyn, nor a polynomial time kernelization algorithm that reduces the solution size and outputs a kernel with 2ok vertices, unless the  fails. endenumerate To the best of our knowledge, textscLocatingDominating Set is the first problem that admits such an algorithmic lowerbound with a quadratic function in the exponent when parameterized by the solution size. beginenumerateresume item textscTest Cover does not admit an algorithm running in time 22ok cdot polyU  calF. endenumerate After textscEdge Clique Cover and textscBiClique Cover, this is the only example that we know of that admits a double exponential lower bound when parameterized by the solution size. beginenumerateresume item textscLocatingDominating Set respectively, textscTest Cover parameterized by the treewidth of the input graph respectively, of the natural auxiliary graph does not admit an algorithm running in time 22otw cdot polyn respectively, 22otw cdot polyU  calF. endenumerate This result augments the small list of NPComplete problems that admit double exponential lower bounds when parameterized by treewidth. We also present algorithms whose running times match the above lower bounds. We also investigate the parameterizations by several other structural graph parameters, answering some open problems from the literature.","Tue, 13 Feb 2024 10:24:20 UTC (5,062 KB)"
"118","Detecting $K_{2,3}$ as an induced minor","Clément Dallard, Maël Dumas, Claire Hilaire, Martin Milanič, Anthony Perez, Nicolas Trotignon","Combinatorics (math.CO)","We consider a natural generalization of chordal graphs, in which every minimal separator induces a subgraph with independence number at most 2. Such graphs can be equivalently defined as graphs that do not contain the complete bipartite graph K2,3 as an induced minor, that is, graphs from which K2,3 cannot be obtained by a sequence of edge contractions and vertex deletions. We develop a polynomialtime algorithm for recognizing these graphs. Our algorithm relies on a characterization of K2,3induced minorfree graphs in terms of excluding particular induced subgraphs, called Truemper configurations.","Tue, 13 Feb 2024 09:57:04 UTC (153 KB)"
"119","Integrating High-Dimensional Functions Deterministically","David Gamarnik, Devin Smedira","Data Structures and Algorithms (cs.DS)","We design a QuasiPolynomial time deterministic approximation algorithm for computing the integral of a multidimensional separable function, supported by some underlying hypergraph structure, appropriately defined. Equivalently, our integral is the partition function of a graphical model with continuous potentials. While randomized algorithms for highdimensional integration are widely known, deterministic counterparts generally do not exist. We use the correlation decay method applied to the Riemann sum of the function to produce our algorithm. For our method to work, we require that the domain is bounded and the hyperedge potentials are positive and bounded on the domain. We further assume that upper and lower bounds on the potentials separated by a multiplicative factor of 1  O1Delta2, where Delta is the maximum degree of the graph. When Delta  3, our method works provided the upper and lower bounds are separated by a factor of at most 1.0479. To the best of our knowledge, our algorithm is the first deterministic algorithm for highdimensional integration of a continuous function, apart from the case of trivial product form distributions.","Tue, 13 Feb 2024 05:51:43 UTC (119 KB)"
"120","Causal Discovery under Off-Target Interventions","Davin Choo, Kirankumar Shiragur, Caroline Uhler","Machine Learning (cs.LG)","Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fathand interventions and CRISPR gene knockouts any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a distribution dependent on attempted action. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results.","Tue, 13 Feb 2024 05:43:49 UTC (4,983 KB)"
"121","An Improved Approximation Algorithm for Metric Triangle Packing","Jingyang Zhao, Mingyu Xiao","Data Structures and Algorithms (cs.DS)","Given an edgeweighted metric complete graph with n vertices, the maximum weight metric triangle packing problem is to find a set of n3 vertexdisjoint triangles with the total weight of all triangles in the packing maximized. Several simple methods can lead to a 23approximation ratio. However, this barrier is not easy to break. Chen et al. proposed a randomized approximation algorithm with an expected ratio of 0.66768varepsilon for any constant varepsilon0. In this paper, we improve the approximation ratio to 0.66835varepsilon. Furthermore, we can derandomize our algorithm.","Tue, 13 Feb 2024 05:05:28 UTC (19 KB)"
"122","Detecting Low-Degree Truncation","Anindya De, Huan Li, Shivam Nadimpalli, Rocco A. Servedio","Computational Complexity (cs.CC)","We consider the following basic, and very broad, statistical problem Given a known highdimensional distribution cal D over mathbbRn and a collection of data points in mathbbRn, distinguish between the two possibilities that i the data was drawn from cal D, versus ii the data was drawn from cal DS, i.e. from cal D subject to truncation by an unknown truncation set S subseteq mathbbRn. We study this problem in the setting where cal D is a highdimensional i.i.d. product distribution and S is an unknown degreed polynomial threshold function one of the most wellstudied types of Booleanvalued function over mathbbRn. Our main results are an efficient algorithm when cal D is a hypercontractive distribution, and a matching lower bound bullet For any constant d, we give a polynomialtime algorithm which successfully distinguishes cal D from cal DS using Ond2 samples subject to mild technical conditions on cal D and S bullet Even for the simplest case of cal D being the uniform distribution over 1, 1n, we show that for any constant d, any distinguishing algorithm for degreed polynomial threshold functions must use Omegand2 samples.","Mon, 12 Feb 2024 23:59:59 UTC (208 KB)"
"123","Grounding Data Science Code Generation with Input-Output Specifications","Yeming Wen, Pengcheng Yin, Kensen Shi, Henryk Michalewski, Swarat Chaudhuri, Alex Polozov","Machine Learning (cs.LG)","Large language models LLMs have recently demonstrated a remarkable ability to generate code from natural language NL prompts. However, in the real world, NL is often too ambiguous to capture the true intent behind programming problems, requiring additional inputoutput IO specifications. Unfortunately, LLMs can have difficulty aligning their outputs with both the NL prompt and the IO specification. In this paper, we give a way to mitigate this issue in the context of data science programming, where tasks require explicit IO specifications for clarity. Specifically, we propose GIFT4Code, a novel approach for the instruction finetuning of LLMs with respect to IO specifications. Our method leverages synthetic data produced by the LLM itself and utilizes executionderived feedback as a key learning signal. This feedback, in the form of program IO specifications, is provided to the LLM to facilitate instruction finetuning. We evaluated our approach on two challenging data science benchmarks, Arcade and DS1000. The results demonstrate a significant improvement in the LLMs ability to generate code that is not only executable but also accurately aligned with user specifications, substantially improving the quality of code generation for complex data science tasks.","Mon, 12 Feb 2024 21:32:49 UTC (511 KB)"
"124","The Blocklace: A Universal, Byzantine Fault-Tolerant, Conflict-free Replicated Data Type","Paulo Sérgio Almeida, Ehud Shapiro","Distributed, Parallel, and Cluster Computing (cs.DC)","Conflictfree Replicated Data Types CRDTs are designed for replica convergence without global coordination or consensus. Recent work has achieves the same in a Byzantine environment, through DAGlike structures based on cryptographic hashes of content. The blocklace is a partiallyordered generalization of the blockchain in which each block has any finite number of signed hash pointers to preceding blocks. We show that the blocklace datatype, with the sole operation of adding a single block, is a CRDT it is both a pure operationbased CRDT, with selftagging and a deltastate CRDT, under a slight generalization of the delta framework. Allowing arbitrary values as payload, the blocklace can also be seen as a universal Byzantine faulttolerant implementation for arbitrary CRDTs, under the operationbased approach. Current approaches only care about CRDT convergence, being equivocationtolerant they do not detect or prevent equivocations, allowing a Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state with an infinite number of equivocations. We show that a blocklace can be used not only in an equivocationtolerant way, but also so as to detect and eventually exclude Byzantine behavior, namely equivocations, even under the presence of collusion. The blocklace CRDT protocol ensures that the Byzantine nodes may harm only a finite prefix of the computation.","Mon, 12 Feb 2024 21:27:32 UTC (957 KB)[v2] Wed, 14 Feb 2024 14:32:34 UTC (957 KB)"
"125","Tight Algorithm for Connected Odd Cycle Transversal Parameterized by Clique-width","Narek Bojikian, Stefan Kratsch","Data Structures and Algorithms (cs.DS)","Recently, Bojikian and Kratsch 2023 have presented a novel approach to tackle connectivity problems parameterized by cliquewidth operatornamecw, based on counting small representations of partial solutions modulo two. Using this technique, they were able to get a tight bound for the Steiner Tree problem, answering an open question posed by Hegerfeld and Kratsch ESA, 2023. We use the same technique to solve the Connected Odd Cycle Transversal problem in time mathcalO12operatornamecw. We define a new representation of partial solutions by separating the connectivity requirement from the 2colorability requirement of this problem. Moreover, we prove that our result is tight by providing SETHbased lower bound excluding algorithms with running time mathcalO12epsilonoperatornamelcw even when parameterized by linear cliquewidth. This answers the second question posed by Hegerfeld and Kratsch in the same paper.","Mon, 12 Feb 2024 20:26:19 UTC (70 KB)"
"126","Online Differentially Private Synthetic Data Generation","Yiyun He, Roman Vershynin, Yizhe Zhu","Statistics Theory (math.ST)","We present a polynomialtime algorithm for online differentially private synthetic data generation. For a data stream within the hypercube 0,1d and an infinite time horizon, we develop an online algorithm that generates a differentially private synthetic dataset at each time t. This algorithm achieves a nearoptimal accuracy bound of Ot1dlogt for dgeq 2 and Ot1log4.5t for d1 in the 1Wasserstein distance. This result generalizes the previous work on the continual release model for counting queries to include Lipschitz queries. Compared to the offline case, where the entire dataset is available at once, our approach requires only an extra polylog factor in the accuracy bound.","Mon, 12 Feb 2024 19:21:14 UTC (35 KB)"
"127","Educational data mining and learning analytics: An updated survey","C. Romero, S. Ventura","Human-Computer Interaction (cs.HC)","This survey is an updated and improved version of the previous one published in 2013 in this journal with the title data mining in education. It reviews in a comprehensible and very general way how Educational Data Mining and Learning Analytics have been applied over educational data. In the last decade, this research area has evolved enormously and a wide range of related terms are now used in the bibliography such as Academic Analytics, Institutional Analytics, Teaching Analytics, DataDriven Education, DataDriven DecisionMaking in Education, Big Data in Education, and Educational Data Science. This paper provides the current state of the art by reviewing the main publications, the key milestones, the knowledge discovery cycle, the main educational environments, the specific tools, the free available datasets, the most used methods, the main objectives, and the future trends in this research area.","Sat, 10 Feb 2024 18:48:45 UTC (1,171 KB)"
"128","Factorizing the Brauer monoid in polynomial time","Daniele Marchei, Emanuela Merelli, Andrew Francis","Rings and Algebras (math.RA)","Finding a minimal factorization for a generic semigroup can be done by using the FroidurePin Algorithm, which is not feasible for semigroups of large sizes. On the other hand, if we restrict our attention to just a particular semigroup, we could leverage its structure to obtain a much faster algorithm. In particular, mathcalON2 algorithms are known for factorizing the Symmetric group SN and the TemperleyLieb monoid mathcalTmathcalLN, but none for their superset the Brauer monoid mathcalBN. In this paper we hence propose a mathcalON4 factorization algorithm for mathcalBN. At each iteration, the algorithm rewrites the input X in mathcalBN as X  X circ pi such that ellX  ellX  1, where pi is a factor for X and ell is a length function that returns the minimal number of factors needed to generate X.","Mon, 12 Feb 2024 18:40:43 UTC (996 KB)[v2] Tue, 13 Feb 2024 10:07:54 UTC (996 KB)"
"129","An approximation algorithm for Maximum DiCut vs. Cut","Tamio-Vesa Nakajima, Stanislav Živný","Data Structures and Algorithms (cs.DS)","Goemans and Williamson designed a 0.878approximation algorithm for MaxCut in undirected graphs JACM95. Khot, Kindler, Mosel, and ODonnel showed that the approximation ratio of the GoemansWilliamson algorithm is optimal assuming Khots Unique Games Conjecture SICOMP07. In the problem of maximum cuts in directed graphs MaxDiCut, in which we seek as many edges going from one particular side of the cut to the other, the situation is more complicated but the recent work of Brakensiek, Huang, Potechin, and Zwick showed that their 0.874approximation algorithm is tight under the Unique Games Conjecture up to a small deltaFOCS23. We consider a promise version of the problem and design an SDPbased algorithm which, if given a directed graph G that has a directed cut of value rho, finds an undirected cut in G ignoring edge directions with value at least rho.","Mon, 12 Feb 2024 18:17:01 UTC (16 KB)"
"130","On Computationally Efficient Multi-Class Calibration","Parikshit Gopalan, Lunjia Hu, Guy N. Rothblum","Machine Learning (cs.LG)","Consider a multiclass labelling problem, where the labels can take values in k, and a predictor predicts a distribution over the labels. In this work, we study the following foundational question Are there notions of multiclass calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in k? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity they either suffer from having sample complexity exponential in k, or needing to solve computationally intractable problems, or give rather weak guarantees. Our main contribution is a notion of calibration that achieves all these desiderata we formulate a robust notion of projected smooth calibration for multiclass predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in k. Projected smooth calibration gives strong guarantees for all downstream decision makers who want to use the predictor for binary classification problems of the form does the label belong to a subset T subseteq k e.g. is this an image of an animal? It ensures that the probabilities predicted by summing the probabilities assigned to labels in T are close to some perfectly calibrated binary predictor for that task. We also show that natural strengthenings of our definition are computationally hard to achieve they run into information theoretic barriers or computational intractability. Underlying both our upper and lower bounds is a tight connection that we prove between multiclass calibration and the wellstudied problem of agnostic learning in the standard binary prediction setting.","Mon, 12 Feb 2024 17:25:23 UTC (57 KB)"
"131","Quantum walks, the discrete wave equation and Chebyshev polynomials","Simon Apers, Laurent Miclo","Quantum Physics (quant-ph)","A quantum walk is the quantum analogue of a random walk. While it is relatively well understood how quantum walks can speed up random walk hitting times, it is a longstanding open question to what extent quantum walks can speed up the spreading or mixing rate of random walks on graphs. In this expository paper, inspired by a blog post by Terence Tao, we describe a particular perspective on this question that derives quantum walks from the discrete wave equation on graphs. This yields a description of the quantum walk dynamics as simply applying a Chebyshev polynomial to the random walk transition matrix. This perspective decouples the problem from its quantum origin, and highlights connections to earlier nonquantum work and the use of Chebyshev polynomials in random walk theory as in the VaropoulosCarne bound. We illustrate the approach by proving a weak limit of the quantum walk dynamics on the lattice. This gives a different proof of the quadratically improved spreading behavior of quantum walks on lattices.","Mon, 12 Feb 2024 17:15:19 UTC (44 KB)"
"132","Insights into $(k,ρ)$-shortcutting algorithms","Alexander Leonhardt, Ulrich Meyer, Manuel Penschuck","Data Structures and Algorithms (cs.DS)","A graph is called a k,rhograph iff every node can reach rho of its nearest neighbors in at most k hops. This property proved useful in the analysis and design of parallel shortestpath algorithms. Any graph can be transformed into a k,rhograph by adding shortcuts. Formally, the k,rhoMinimumShortcut problem asks to find an appropriate shortcut set of minimal cardinality. We show that the k,rhoMinimumShortcut problem is NPcomplete in the practical regime of k ge 3 and rho  Thetanepsilon for epsilon  0. With a related construction, we bound the approximation factor of known k,rhoMinimumShortcut problem heuristics from below and propose algorithmic countermeasures improving the approximation quality. Further, we describe an integer linear problem ILP solving the k,rhoMinimumShortcut problem optimally. Finally, we compare the practical performance and quality of all algorithms in an empirical campaign.","Mon, 12 Feb 2024 16:33:23 UTC (1,214 KB)"
"133","Engineering Weighted Connectivity Augmentation Algorithms","Marcelo Fonseca Faraj, Ernestine Großmann, Felix Joos, Thomas Möller, Christian Schulz","Data Structures and Algorithms (cs.DS)","Increasing the connectivity of a graph is a pivotal challenge in robust network design. The weighted connectivity augmentation problem is a common version of the problem that takes link costs into consideration. The problem is then to find a minimum cost subset of a given set of weighted links that increases the connectivity of a graph by one when the links are added to the edge set of the input instance. In this work, we give a first implementation of recently discovered betterthan2 approximations. Furthermore, we propose three new heuristic and one exact approach. These include a greedy algorithm considering link costs and the number of unique cuts covered, an approach based on minimum spanning trees and a local search algorithm that may improve a given solution by swapping links of paths. Our exact approach uses an ILP formulation with efficient cut enumeration as well as a fast initialization routine. We then perform an extensive experimental evaluation which shows that our algorithms are faster and yield the best solutions compared to the current stateoftheart as well as the recently discovered betterthan2 approximation algorithms. Our novel local search algorithm can improve solution quality even further.","Mon, 12 Feb 2024 16:23:23 UTC (843 KB)"
"134","Pattern Matching with Mismatches and Wildcards","Gabriel Bathie, Panagiotis Charalampopoulos, Tatiana Starikovskaya","Data Structures and Algorithms (cs.DS)","In this work, we address the problem of approximate pattern matching with wildcards. Given a pattern P of length m containing D wildcards, a text T of length n, and an integer k, our objective is to identify all fragments of T within Hamming distance k from P. Our primary contribution is an algorithm with runtime OnDkGkcdot nm for this problem. Here, G le D represents the number of maximal wildcard fragments in P. We derive this algorithm by elaborating in a nontrivial way on the ideas presented by Charalampopoulos et al., FOCS20 for pattern matching with mismatches without wildcards. Our algorithm improves over the state of the art when D, G, and k are small relative to n. For instance, if m  n2, kGn25, and Dn35, our algorithm operates in On time, surpassing the Omegan65 time requirement of all previously known algorithms. In the case of exact pattern matching with wildcards k0, we present a much simpler algorithm with runtime OnDGcdot nm that clearly illustrates our main technical innovation the utilisation of positions of P that do not belong to any fragment of P with a density of wildcards much larger than Dm as anchors for the sought approximate occurrences. Notably, our algorithm outperforms the bestknown Onlog mtime FFTbased algorithms of Cole and Hariharan, STOC02 and Clifford and Clifford, IPL04 if DG  omlog m. We complement our algorithmic results with a structural characterization of the kmismatch occurrences of P. We demonstrate that in a text of length Om, these occurrences can be partitioned into ODkGk arithmetic progressions. Additionally, we construct an infinite family of examples with OmegaDkk arithmetic progressions of occurrences, leveraging a combinatorial result on progressionfree sets Elkin, SODA10.","Mon, 12 Feb 2024 15:42:50 UTC (236 KB)"
"135","Local Centrality Minimization with Quality Guarantees","Atsushi Miyauchi, Lorenzo Severini, Francesco Bonchi","Social and Information Networks (cs.SI)","Centrality measures, quantifying the importance of vertices or edges, play a fundamental role in network analysis. To date, triggered by some positive approximability results, a large body of work has been devoted to studying centrality maximization, where the goal is to maximize the centrality score of a target vertex by manipulating the structure of a given network. On the other hand, due to the lack of such results, only very little attention has been paid to centrality minimization, despite its practical usefulness. In this study, we introduce a novel optimization model for local centrality minimization, where the manipulation is allowed only around the target vertex. We prove the NPhardness of our model and that the most intuitive greedy algorithm has a quite limited performance in terms of approximation ratio. Then we design two effective approximation algorithms The first algorithm is a highlyscalable algorithm that has an approximation ratio unachievable by the greedy algorithm, while the second algorithm is a bicriteria approximation algorithm that solves a continuous relaxation based on the Lovsz extension, using a projected subgradient method. To the best of our knowledge, ours are the first polynomialtime algorithms with provable approximation guarantees for centrality minimization. Experiments using a variety of realworld networks demonstrate the effectiveness of our proposed algorithms Our first algorithm is applicable to millionscale graphs and obtains much better solutions than those of scalable baselines, while our second algorithm is rather strong against adversarial instances.","Mon, 12 Feb 2024 15:32:48 UTC (336 KB)"
"136","Approximating the Maximum Independent Set of Convex Polygons with a Bounded Number of Directions","Fabrizio Grandoni, Edin Husić, Mathieu Mari, Antoine Tinguely","Computational Geometry (cs.CG)","In the maximum independent set of convex polygons problem, we are given a set of n convex polygons in the plane with the objective of selecting a maximum cardinality subset of nonoverlapping polygons. Here we study a special case of the problem where the edges of the polygons can take at most d fixed directions. We present an 8d3approximation algorithm for this problem running in time OndOd4d. The previousbest polynomialtime approximation for constant d was a classical nvarepsilon approximation by Fox and Pach SODA11 that has recently been improved to a OPTvarepsilonapproximation algorithm by Cslovjecsek, Pilipczuk and Wgrzycki SODA 24, which also extends to an arbitrary set of convex polygons. Our result builds on, and generalizes the recent constant factor approximation algorithms for the maximum independent set of axisparallel rectangles problem which is a special case of our problem with d2 by Mitchell FOCS21 and Glvez, Khan, Mari, Mmke, Reddy, and Wiese SODA22.","Mon, 12 Feb 2024 14:20:15 UTC (2,034 KB)"
"137","Riemannian trust-region methods for strict saddle functions with complexity guarantees","Florentin Goyens, Clément W. Royer","Optimization and Control (math.OC)","The difficulty of minimizing a nonconvex function is in part explained by the presence of saddle points. This slows down optimization algorithms and impacts worstcase complexity guarantees. However, many nonconvex problems of interest possess a favorable structure for optimization, in the sense that saddle points can be escaped efficiently by appropriate algorithms. This strict saddle property has been extensively used in data science to derive good properties for firstorder algorithms, such as convergence to secondorder critical points. However, the analysis and the design of secondorder algorithms in the strict saddle setting have received significantly less attention. In this paper, we consider secondorder trustregion methods for a class of strict saddle functions defined on Riemannian manifolds. These functions exhibit geodesic strong convexity around minimizers and negative curvature at saddle points. We show that the standard trustregion method with exact subproblem minimization finds an approximate local minimizer in a number of iterations that depends logarithmically on the accuracy parameter, which significantly improves known results for general nonconvex optimization. We also propose an inexact variant of the algorithm that explicitly leverages the strict saddle property to compute the most appropriate step at every iteration. Our bounds for the inexact variant also improve over the general nonconvex case, and illustrate the benefit of using strict saddle properties within optimization algorithms. Keywords Riemannian optimization, strict saddle function, secondorder method, complexity guarantees.","Mon, 12 Feb 2024 12:42:48 UTC (39 KB)[v2] Wed, 21 Feb 2024 14:54:02 UTC (39 KB)"
"138","De Casteljau's Algorithm in Geometric Data Analysis: Theory and Application","Martin Hanik, Esfandiar Nava-Yazdani, Christoph von Tycowicz","Differential Geometry (math.DG)","For decades, de Casteljaus algorithm has been used as a fundamental building block in curve and surface design and has found a wide range of applications in fields such as scientific computing, and discrete geometry to name but a few. With increasing interest in nonlinear data science, its constructive approach has been shown to provide a principled way to generalize parametric smooth curves to manifolds. These curves have found remarkable new applications in the analysis of parameterdependent, geometric data. This article provides a survey of the recent theoretical developments in this exciting area as well as its applications in fields such as geometric morphometrics and longitudinal data analysis in medicine, archaeology, and meteorology.","Mon, 12 Feb 2024 10:33:08 UTC (6,910 KB)"
"139","Accelerating Distributed Deep Learning using Lossless Homomorphic Compression","Haoyu Li, Yuchen Xu, Jiayi Chen, Rohit Dwivedula, Wenfei Wu, Keqiang He, Aditya Akella, Daehyeok Kim","Distributed, Parallel, and Cluster Computing (cs.DC)","As deep neural networks DNNs grow in complexity and size, the resultant increase in communication overhead during distributed training has become a significant bottleneck, challenging the scalability of distributed training systems. Existing solutions, while aiming to mitigate this bottleneck through workerlevel compression and innetwork aggregation, fall short due to their inability to efficiently reconcile the tradeoffs between compression effectiveness and computational overhead, hindering overall performance and scalability. In this paper, we introduce a novel compression algorithm that effectively merges workerlevel compression with innetwork aggregation. Our solution is both homomorphic, allowing for efficient innetwork aggregation without CPUGPU processing, and lossless, ensuring no compromise on training accuracy. Theoretically optimal in compression and computational efficiency, our approach is empirically validated across diverse DNN models such as NCF, LSTM, VGG19, and BERTbase, showing up to a 6.33times improvement in aggregation throughput and a 3.74times increase in periteration training speed.","Mon, 12 Feb 2024 09:57:47 UTC (386 KB)"
"140","On the Distance from Calibration in Sequential Prediction","Mingda Qiao, Letian Zheng","Machine Learning (cs.LG)","We study a sequential binary prediction setting where the forecaster is evaluated in terms of the calibration distance, which is defined as the L1 distance between the predicted values and the set of predictions that are perfectly calibrated in hindsight. This is analogous to a calibration measure recently proposed by Basiok, Gopalan, Hu and Nakkiran STOC 2023 for the offline setting. The calibration distance is a natural and intuitive measure of deviation from perfect calibration, and satisfies a Lipschitz continuity property which does not hold for many popular calibration measures, such as the L1 calibration error and its variants. We prove that there is a forecasting algorithm that achieves an OsqrtT calibration distance in expectation on an adversarially chosen sequence of T binary outcomes. At the core of this upper bound is a structural result showing that the calibration distance is accurately approximated by the lower calibration distance, which is a continuous relaxation of the former. We then show that an OsqrtT lower calibration distance can be achieved via a simple minimax argument and a reduction to online learning on a Lipschitz class. On the lower bound side, an OmegaT13 calibration distance is shown to be unavoidable, even when the adversary outputs a sequence of independent random bits, and has an additional ability to early stop i.e., to stop producing random bits and output the same bit in the remaining steps. Interestingly, without this early stopping, the forecaster can achieve a much smaller calibration distance of mathrmpolylogT.","Mon, 12 Feb 2024 07:37:19 UTC (44 KB)"
"141","The I/O Complexity of Attention, or How Optimal is Flash Attention?","Barna Saha, Christopher Ye","Machine Learning (cs.LG)","Selfattention is at the heart of the popular Transformer architecture, yet suffers from quadratic time and memory complexity. The breakthrough FlashAttention algorithm revealed IO complexity as the true bottleneck in scaling Transformers. Given two levels of memory hierarchy, a fast cache e.g. GPU onchip SRAM and a slow memory e.g. GPU highbandwidth memory, the IO complexity measures the number of accesses to memory. FlashAttention computes attention using fracN2d2M IO operations where N is the dimension of the attention matrix, d the headdimension and M the cache size. However, is this IO complexity optimal? The known lower bound only rules out an IO complexity of oNd when MThetaNd, since the output that needs to be written to slow memory is OmegaNd. This leads to the main question of our work Is FlashAttention IO optimal for all values of M? We resolve the above question in its full generality by showing an IO complexity lower bound that matches the upper bound provided by FlashAttention for any values of M geq d2 within any constant factors. Further, we give a better algorithm with lower IO complexity for M  d2, and show that it is optimal as well. Moreover, our lower bounds do not rely on using combinatorial matrix multiplication for computing the attention matrix. We show even if one uses fast matrix multiplication, the above IO complexity bounds cannot be improved. We do so by introducing a new communication complexity protocol for matrix compression, and connecting communication complexity to IO complexity. To the best of our knowledge, this is the first work to establish a connection between communication complexity and IO complexity, and we believe this connection could be of independent interest and will find many more applications in proving IO complexity lower bounds in the future.","Mon, 12 Feb 2024 06:50:45 UTC (66 KB)"
"142","Fundamental Problems on Bounded-Treewidth Graphs: The Real Source of Hardness","Barış Can Esmer, Jacob Focke, Dániel Marx, Paweł Rzążewski","Computational Complexity (cs.CC)","It is known for many algorithmic problems that if a tree decomposition of width t is given in the input, then the problem can be solved with exponential dependence on t. A line of research by Lokshtanov, Marx, and Saurabh SODA 2011 produced lower bounds showing that in many cases known algorithms achieve the best possible exponential dependence on t, assuming the SETH. The main message of our paper is showing that the same lower bounds can be obtained in a more restricted setting a graph consisting of a block of t vertices connected to components of constant size already has the same hardness as a general tree decomposition of width t. Formally, a sigma,deltahub is a set Q of vertices such that every component of Q has size at most sigma and is adjacent to at most delta vertices of Q. bullet For every epsilon 0, there are sigma,delta 0 such that Independent SetVertex Cover cannot be solved in time 2epsilonpcdot n, even if a sigma,deltahub of size p is given in the input, assuming the SETH. This matches the earlier tight lower bounds parameterized by the width of the tree decomposition. Similar tight bounds are obtained for Odd Cycle Transversal, Max Cut, qColoring, and edgevertex deletions versions of qColoring. bullet For every epsilon0, there are sigma,delta 0 such that TrianglePartition cannot be solved in time 2epsilonpcdot n, even if a sigma,deltahub of size p is given in the input, assuming the Set Cover Conjecture SCC. In fact, we prove that this statement is equivalent to the SCC, thus it is unlikely that this could be proved assuming the SETH. bullet For Dominating Set, we can prove a nontight lower bound ruling out 2epsilonpcdot nO1 algorithms, assuming either the SETH or the SCC, but this does not match the 3pcdot nO1 upper bound.","Sun, 11 Feb 2024 23:48:25 UTC (205 KB)[v2] Mon, 19 Feb 2024 15:06:42 UTC (205 KB)"
"143","Improving LSH via Tensorized Random Projection","Bhisham Dev Verma, Rameshwar Pratap","Machine Learning (stat.ML)","Locality sensitive hashing LSH is a fundamental algorithmic toolkit used by data scientists for approximate nearest neighbour search problems that have been used extensively in many large scale data processing applications such as near duplicate detection, nearest neighbour search, clustering, etc. In this work, we aim to propose faster and space efficient locality sensitive hash functions for Euclidean distance and cosine similarity for tensor data. Typically, the naive approach for obtaining LSH for tensor data involves first reshaping the tensor into vectors, followed by applying existing LSH methods for vector data E2LSH and SRP. However, this approach becomes impractical for higher order tensors because the size of the reshaped vector becomes exponential in the order of the tensor. Consequently, the size of LSH parameters increases exponentially. To address this problem, we suggest two methods for LSH for Euclidean distance and cosine similarity, namely CPE2LSH, TTE2LSH, and CPSRP, TTSRP, respectively, building on CP and tensor train TT decompositions techniques. Our approaches are space efficient and can be efficiently applied to low rank CP or TT tensors. We provide a rigorous theoretical analysis of our proposal on their correctness and efficacy.","Sun, 11 Feb 2024 12:54:07 UTC (79 KB)"
"144","The $k$-Opt algorithm for the Traveling Salesman Problem has exponential running time for $k \ge 5$","Sophia Heimann, Hung P. Hoang, Stefan Hougardy","Data Structures and Algorithms (cs.DS)","The kOpt algorithm is a local search algorithm for the Traveling Salesman Problem. Starting with an initial tour, it iteratively replaces at most k edges in the tour with the same number of edges to obtain a better tour. Krentel FOCS 1989 showed that the Traveling Salesman Problem with the kOpt neighborhood is complete for the class PLS polynomial time local search and that the kOpt algorithm can have exponential running time for any pivot rule. However, his proof requires k gg 1000 and has a substantial gap. We show the two properties above for a much smaller value of k, addressing an open question by Monien, Dumrauf, and Tscheuschner ICALP 2010. In particular, we prove the PLScompleteness for k geq 17 and the exponential running time for k geq 5.","Sat, 10 Feb 2024 22:35:40 UTC (509 KB)"
"145","Quantum Speedup for Spectral Approximation of Kronecker Products","Yeqi Gao, Zhao Song, Ruizhe Zhang","Data Structures and Algorithms (cs.DS)","Given its widespread application in machine learning and optimization, the Kronecker product emerges as a pivotal linear algebra operator. However, its computational demands render it an expensive operation, leading to heightened costs in spectral approximation of it through traditional computation algorithms. Existing classical methods for spectral approximation exhibit a linear dependency on the matrix dimension denoted by n, considering matrices of size A1 in mathbbRn times d and A2 in mathbbRn times d. Our work introduces an innovative approach to efficiently address the spectral approximation of the Kronecker product A1 otimes A2 using quantum methods. By treating matrices as quantum states, our proposed method significantly reduces the time complexity of spectral approximation to Od,epsilonsqrtn.","Sat, 10 Feb 2024 19:21:29 UTC (23 KB)"
"146","Taxonomic classification with maximal exact matches in KATKA kernels and minimizer digests","Dominika Draesslerová, Omar Ahmed, Travis Gagie, Jan Holub, Ben Langmead, Giovanni Manzini, Gonzalo Navarro","Data Structures and Algorithms (cs.DS)","For taxonomic classification, we are asked to index the genomes in a phylogenetic tree such that later, given a DNA read, we can quickly choose a small subtree likely to contain the genome from which that read was drawn. Although popular classifiers such as Kraken use kmers, recent research indicates that using maximal exact matches MEMs can lead to better classifications. For example, we can build an augmented FMindex over the the genomes in the tree concatenated in lefttoright order for each MEM in a read, find the interval in the suffix array containing the starting positions of that MEMs occurrences in those genomes find the minimum and maximum values stored in that interval take the lowest common ancestor LCA of the genomes containing the characters at those positions. This solution is practical, however, only when the total size of the genomes in the tree is fairly small. In this paper we consider applying the same solution to three lossily compressed representations of the genomes concatenation a KATKA kernel, which discards characters that are not in the first or last occurrence of any kmaxtuple, for a parameter kmax a minimizer digest a KATKA kernel of a minimizer digest. With a test dataset and these three representations of it, simulated reads and various parameter settings, we checked how many reads longest MEMs occurred only in the sequences from which those reads were generated true positive reads. For some parameter settings we achieved significant compression while only slightly decreasing the truepositive rate.","Sat, 10 Feb 2024 12:20:43 UTC (334 KB)"
"147","A Scalable Algorithm for Individually Fair K-means Clustering","MohammadHossein Bateni, Vincent Cohen-Addad, Alessandro Epasto, Silvio Lattanzi","Data Structures and Algorithms (cs.DS)","We present a scalable algorithm for the individually fair p, kclustering problem introduced by Jung et al. and Mahabadi et al. Given n points P in a metric space, let deltax for xin P be the radius of the smallest ball around x containing at least n  k points. A clustering is then called individually fair if it has centers within distance deltax of x for each xin P. While good approximation algorithms are known for this problem no efficient practical algorithms with good theoretical guarantees have been presented. We design the first fast localsearch algorithm that runs in Onk2 time and obtains a bicriteria O1, 6 approximation. Then we show empirically that not only is our algorithm much faster than prior work, but it also produces lowercost solutions.","Fri, 9 Feb 2024 19:01:48 UTC (66 KB)"
"148","Learning-augmented Online Algorithm for Two-level Ski-rental Problem","Keyuan Zhang, Zhongdong Liu, Nakjung Choi, Bo Ji","Data Structures and Algorithms (cs.DS)","In this paper, we study the twolevel skirental problem,where a user needs to fulfill a sequence of demands for multiple items by choosing one of the three payment options paying for the ondemand usage i.e., rent, buying individual items i.e., single purchase, and buying all the items i.e., combo purchase. Without knowing future demands, the user aims to minimize the total cost i.e., the sum of the rental, single purchase, and combo purchase costs by balancing the tradeoff between the expensive upfront costs for purchase and the potential future expenses for rent. We first design a robust online algorithm RDTSR that offers a worstcase performance guarantee. While online algorithms are robust against the worstcase scenarios, they are often overly cautious and thus suffer a poor average performance in typical scenarios. On the other hand, Machine Learning ML algorithms typically show promising average performance in various applications but lack worstcase performance guarantees. To harness the benefits of both methods, we develop a learningaugmented algorithm LADTSR by integrating ML predictions into the robust online algorithm, which outperforms the robust online algorithm under accurate predictions while ensuring worstcase performance guarantees even when predictions are inaccurate. Finally, we conduct numerical experiments on both synthetic and realworld trace data to corroborate the effectiveness of our approach.","Fri, 9 Feb 2024 16:10:54 UTC (277 KB)"
"149","Entropy-Regularized Token-Level Policy Optimization for Large Language Models","Muning Wen, Cheng Deng, Jun Wang, Weinan Zhang, Ying Wen","Machine Learning (cs.LG)","Large Language Models LLMs have shown promise as intelligent agents in interactive decisionmaking tasks. Traditional approaches often depend on meticulously designed prompts, highquality examples, or additional reward models for incontext learning, supervised finetuning, or RLHF. Reinforcement learning RL presents a dynamic alternative for LLMs to overcome these dependencies by engaging directly with taskspecific environments. Nonetheless, it faces significant hurdles 1 instability stemming from the exponentially vast action space requiring exploration 2 challenges in assigning tokenlevel credit based on actionlevel reward signals, resulting in discord between maximizing rewards and accurately modeling corpus data. In response to these challenges, we introduce EntropyRegularized Tokenlevel Policy Optimization ETPO, an entropyaugmented RL method tailored for optimizing LLMs at the token level. At the heart of ETPO is our novel pertoken soft Bellman update, designed to harmonize the RL process with the principles of language modeling. This methodology decomposes the Qfunction update from a coarse actionlevel view to a more granular tokenlevel perspective, backed by theoretical proof of optimization consistency. Crucially, this decomposition renders linear time complexity in action exploration. We assess the effectiveness of ETPO within a simulated environment that models data science code generation as a series of multistep interactive tasks results show that ETPO achieves effective performance improvement on the CodeLlama7B model and surpasses a variant PPO baseline inherited from RLHF. This underlines ETPOs potential as a robust method for refining the interactive decisionmaking capabilities of LLMs.","Fri, 9 Feb 2024 07:45:26 UTC (504 KB)"
"150","Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading","Abhijin Adiga, Yohai Trabelsi, Tanvir Ferdousi, Madhav Marathe, S. S. Ravi, Samarth Swarup, Anil Kumar Vullikanti, Mandy L. Wilson, Sarit Kraus, Reetwika Basu, Supriya Savalkar, Matthew Yourek, Michael Brady, Kirti Rajagopalan, Jonathan Yoder","Data Structures and Algorithms (cs.DS)","Optimal allocation of agricultural water in the event of droughts is an important global problem. In addressing this problem, many aspects, including the welfare of farmers, the economy, and the environment, must be considered. Under this backdrop, our work focuses on several resourcematching problems accounting for agents with multicrop portfolios, geographic constraints, and fairness. First, we address a matching problem where the goal is to maximize a welfare function in twosided markets where buyers requirements and sellers supplies are represented by value functions that assign prices or costs to specified volumes of water. For the setting where the value functions satisfy certain monotonicity properties, we present an efficient algorithm that maximizes a social welfare function. When there are minimum water requirement constraints, we present a randomized algorithm which ensures that the constraints are satisfied in expectation. For a single sellermultiple buyers setting with fairness constraints, we design an efficient algorithm that maximizes the minimum level of satisfaction of any buyer. We also present computational complexity results that highlight the limits on the generalizability of our results. We evaluate the algorithms developed in our work with experiments on both realworld and synthetic data sets with respect to drought severity, value functions, and seniority of agents.","Fri, 9 Feb 2024 17:50:40 UTC (4,584 KB)[v2] Mon, 12 Feb 2024 02:17:04 UTC (4,657 KB)"
